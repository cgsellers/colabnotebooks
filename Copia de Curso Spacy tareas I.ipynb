{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1rUl_8RACKDK-TiGRUbrsqrQoODhKwodj","timestamp":1680192957373}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["**Tarea 1: Encontrando palabras y frases**\n","\n","Escriba un programa Python que utilice la librería Spacy para identificar todas las palabras y frases en una oración dada por el usuario."],"metadata":{"id":"EERoHoDxjHzy"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"4ByZbjAGjHFM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1680193533992,"user_tz":-120,"elapsed":29450,"user":{"displayName":"Carlos Germán Sellers Mendo","userId":"10483787242844398475"}},"outputId":"18cfff62-5dff-48f0-8933-4464d846d77e"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/torch/cuda/__init__.py:497: UserWarning: Can't initialize NVML\n","  warnings.warn(\"Can't initialize NVML\")\n"]},{"output_type":"stream","name":"stdout","text":["/usr/local/lib/python3.9/dist-packages/torch/cuda/__init__.py:497: UserWarning: Can't initialize NVML\n","  warnings.warn(\"Can't initialize NVML\")\n","2023-03-30 16:25:22.582355: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n","2023-03-30 16:25:22.582457: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n","2023-03-30 16:25:22.582476: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n","2023-03-30 16:25:24.269201: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting es-core-news-sm==3.5.0\n","  Downloading https://github.com/explosion/spacy-models/releases/download/es_core_news_sm-3.5.0/es_core_news_sm-3.5.0-py3-none-any.whl (12.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.9/12.9 MB\u001b[0m \u001b[31m44.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: spacy<3.6.0,>=3.5.0 in /usr/local/lib/python3.9/dist-packages (from es-core-news-sm==3.5.0) (3.5.1)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->es-core-news-sm==3.5.0) (1.10.7)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->es-core-news-sm==3.5.0) (3.0.8)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->es-core-news-sm==3.5.0) (1.0.9)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->es-core-news-sm==3.5.0) (2.4.6)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->es-core-news-sm==3.5.0) (2.27.1)\n","Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->es-core-news-sm==3.5.0) (8.1.9)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->es-core-news-sm==3.5.0) (67.6.1)\n","Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->es-core-news-sm==3.5.0) (1.1.1)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->es-core-news-sm==3.5.0) (4.65.0)\n","Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->es-core-news-sm==3.5.0) (1.22.4)\n","Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->es-core-news-sm==3.5.0) (0.10.1)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->es-core-news-sm==3.5.0) (23.0)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->es-core-news-sm==3.5.0) (1.0.4)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->es-core-news-sm==3.5.0) (2.0.8)\n","Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->es-core-news-sm==3.5.0) (6.3.0)\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->es-core-news-sm==3.5.0) (3.3.0)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->es-core-news-sm==3.5.0) (2.0.7)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->es-core-news-sm==3.5.0) (3.0.12)\n","Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->es-core-news-sm==3.5.0) (0.7.0)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->es-core-news-sm==3.5.0) (3.1.2)\n","Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.9/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.6.0,>=3.5.0->es-core-news-sm==3.5.0) (4.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->es-core-news-sm==3.5.0) (2022.12.7)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->es-core-news-sm==3.5.0) (1.26.15)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->es-core-news-sm==3.5.0) (3.4)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->es-core-news-sm==3.5.0) (2.0.12)\n","Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.9/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->es-core-news-sm==3.5.0) (0.0.4)\n","Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.9/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->es-core-news-sm==3.5.0) (0.7.9)\n","Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.9/dist-packages (from typer<0.8.0,>=0.3.0->spacy<3.6.0,>=3.5.0->es-core-news-sm==3.5.0) (8.1.3)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->spacy<3.6.0,>=3.5.0->es-core-news-sm==3.5.0) (2.1.2)\n","Installing collected packages: es-core-news-sm\n","Successfully installed es-core-news-sm-3.5.0\n","\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n","You can now load the package via spacy.load('es_core_news_sm')\n"]}],"source":["import spacy\n","\n","!python -m spacy download es_core_news_sm\n","\n","nlp = spacy.load(\"es_core_news_sm\")"]},{"cell_type":"markdown","source":["**Tarea 2: Encontrando nombres**\n","\n","Escriba un programa Python que utilice la librería Spacy para identificar todos los nombres y signos de puntuación en una oración dada por el usuario."],"metadata":{"id":"mceMUCEq0Qr6"}},{"cell_type":"code","source":["#Write your code here\n","def identificar_nombres_signos(frase):\n","    doc = nlp(frase)\n","    nombres = []\n","    signos = []\n","    for token in doc:\n","        if token.pos_ == \"NOUN\":\n","            nombres.append(token.text)\n","        elif token.pos_ == \"PUNCT\":\n","            signos.append(token.text)\n","    return (nombres, signos)"],"metadata":{"id":"WbN4_hdF0Sjp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["frase=\"¿Es posible que Microsoft despida a nuestro amigo Marcos por mala conducta en su correo marcos@educarex.es?!!\"\n","nombres,signos=(identificar_nombres_signos(frase))\n","print(\"Sustantivos comunes: {}\\nSignos de puntuación:{}\".format(nombres,signos))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vYkHWfjpVfah","executionInfo":{"status":"ok","timestamp":1680194971520,"user_tz":-120,"elapsed":238,"user":{"displayName":"Carlos Germán Sellers Mendo","userId":"10483787242844398475"}},"outputId":"f72bafba-0ce4-4ddd-e4b8-bc7b5cd3a0b3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Sustantivos comunes: ['amigo', 'conducta', 'correo']\n","Signos de puntuación:['¿', '?', '!', '!']\n"]}]},{"cell_type":"markdown","source":["**Tarea 3: Encontrando conceptos**\n","\n","Escriba un programa Python que utilice la librería Spacy para identificar todos los conceptos en un texto dado por el usuario."],"metadata":{"id":"-iV1h8f51XMF"}},{"cell_type":"code","source":["#Write your code here\n","def identificar_conceptos(frase):\n","    doc = nlp(frase)\n","    conceptos = []\n","    for ent in doc.ents:\n","        conceptos.append(ent.text)\n","    return conceptos"],"metadata":{"id":"bc9gWBJ_1Y8L"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(identificar_conceptos(frase))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jbL7JmYKXG9M","executionInfo":{"status":"ok","timestamp":1680194977518,"user_tz":-120,"elapsed":299,"user":{"displayName":"Carlos Germán Sellers Mendo","userId":"10483787242844398475"}},"outputId":"125aaf6c-a3bf-4233-de5c-08e8b7c51af1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['Microsoft', 'Marcos', 'marcos@educarex.es?!!']\n"]}]},{"cell_type":"markdown","source":["Encontrando patrones basados en reglas"],"metadata":{"id":"6P27LRmd8WKz"}},{"cell_type":"code","source":["#Write your code here\n","from spacy.matcher import Matcher\n","def encontrar_patrones(frase,reglas=False):\n","  doc=nlp(frase)\n","  matcher=Matcher(nlp.vocab)\n","  if reglas:\n","    for regla in reglas:\n","      matcher.add(regla[\"label\"],[regla[\"patron\"]])\n","  matches=matcher(doc)\n","  patrones=[]\n","  for match_id, start, end in matches:\n","      label = nlp.vocab.strings[match_id]\n","      patrones.append({\"label\": label, \"text\": doc[start:end].text})\n","  return patrones\n"],"metadata":{"id":"bIGfLREO8dB7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["patrones=[{\"label\": \"EMAIL_ADDRESS\", \"patron\": [{\"TEXT\": {\"REGEX\": \"[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}\"} }]}]\n","print(encontrar_patrones(frase,patrones))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"62QS26lsalGE","executionInfo":{"status":"ok","timestamp":1680195112290,"user_tz":-120,"elapsed":4,"user":{"displayName":"Carlos Germán Sellers Mendo","userId":"10483787242844398475"}},"outputId":"5b9409b4-5ed0-4d87-b2fa-0a049c783c86"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[{'label': 'EMAIL_ADDRESS', 'text': 'marcos@educarex.es'}]\n"]}]},{"cell_type":"markdown","source":["**Tarea 4: Análisis de datos a gran escala**\n","\n","Escriba un programa Python que utilice la librería Spacy para procesar un gran conjunto de datos (por ejemplo, un archivo de texto con varias líneas) y extraer todas las frases que contienen una palabra clave específica."],"metadata":{"id":"uizg6tZ52cnq"}},{"cell_type":"code","source":["#Write your code here\n","def extraer_frases_por_palabra(texto, palabra):\n","    doc = nlp(texto)\n","    frases = []\n","    for frase in doc.sents:\n","        if palabra in frase.text:\n","            frases.append(frase.text)\n","    return frases"],"metadata":{"id":"ncXAgbmo2esT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["texto='Los investigadores conjeturan que otras plantas también podrían estar escuchando y beneficiándose de los sonidos. Según el comunicado de prensa, Hadany y otros miembros de su equipo mostraron en investigaciones anteriores que las plantas pueden responder a sonidos y vibraciones, también que algunas aumentan la concentración de azúcar en su néctar cuando “oyen” los sonidos emitidos por los polinizadores. Otros estudios han demostrado que las plantas cambian su expresión genética en respuesta a los sonidos. “Si otras plantas tuvieran información sobre el estrés antes de que se produjera, podrían prepararse”, apunta Hadany.'\n","print(extraer_frases_por_palabra(texto,'sonidos'))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Vig57CvkqWwy","executionInfo":{"status":"ok","timestamp":1680202049061,"user_tz":-120,"elapsed":319,"user":{"displayName":"Carlos Germán Sellers Mendo","userId":"10483787242844398475"}},"outputId":"a694164c-d793-44b9-8f75-343e7b5cd4c2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['Los investigadores conjeturan que otras plantas también podrían estar escuchando y beneficiándose de los sonidos.', 'Según el comunicado de prensa, Hadany y otros miembros de su equipo mostraron en investigaciones anteriores que las plantas pueden responder a sonidos y vibraciones, también que algunas aumentan la concentración de azúcar en su néctar cuando “oyen” los sonidos emitidos por los polinizadores.', 'Otros estudios han demostrado que las plantas cambian su expresión genética en respuesta a los sonidos.']\n"]}]},{"cell_type":"markdown","source":["**Tarea 5: Análisis de datos a gran escala (2)**\n","\n","Escriba un programa Python que utilice la librería Spacy para procesar un gran conjunto de datos (por ejemplo, un archivo de texto con varias líneas) y extraer todas las entidades nombradas en el texto."],"metadata":{"id":"-RWKr2xo3f7i"}},{"cell_type":"code","source":["#Write your code here\n","def extraer_entidades(texto):\n","    doc = nlp(texto)\n","    entidades = []\n","    for ent in doc.ents:\n","        entidades.append({'text': ent.text, 'label': ent.label_})\n","    return entidades"],"metadata":{"id":"pWdTEDsi3iDy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(extraer_entidades(texto))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Cb7R6nJI5seL","executionInfo":{"status":"ok","timestamp":1680202989828,"user_tz":-120,"elapsed":267,"user":{"displayName":"Carlos Germán Sellers Mendo","userId":"10483787242844398475"}},"outputId":"54618294-5fa6-4527-9195-f299311c93ee"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[{'text': 'Según', 'label': 'PER'}, {'text': 'Hadany', 'label': 'PER'}, {'text': '“', 'label': 'LOC'}, {'text': 'Otros estudios', 'label': 'MISC'}, {'text': '“Si otras plantas', 'label': 'MISC'}, {'text': 'Hadany', 'label': 'PER'}]\n"]}]},{"cell_type":"markdown","source":["**Tarea 6: Compara dos documentos introducidos por el usuario e indica la similitud entre ambos.**"],"metadata":{"id":"P-m4QKHgDs4y"}},{"cell_type":"code","source":["#Write your code here\n","def comparar_docs(doc1,doc2):\n","      return doc1.similarity(doc2)"],"metadata":{"id":"gAmqmTqED9C2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["doc1=nlp(\"Mañana voy a correr por el parque\")\n","doc2=nlp(\"Ayer andamos por la ciudad\")\n","print(\"la similitud (de 0 a 1) de los dos documentos es: {}\".format(comparar_docs(doc1,doc2)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sg_PF0Cp65be","executionInfo":{"status":"ok","timestamp":1680203415754,"user_tz":-120,"elapsed":440,"user":{"displayName":"Carlos Germán Sellers Mendo","userId":"10483787242844398475"}},"outputId":"ba1c5c86-11e2-4911-a0af-bfba6d11afde"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["la similitud (de 0 a 1) de los dos documentos es: 0.4180577073293421\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-50-0a3a04cdbaa1>:3: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n","  return doc1.similarity(doc2)\n"]}]}]}