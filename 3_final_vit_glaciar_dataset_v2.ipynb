{"cells":[{"cell_type":"markdown","metadata":{"id":"X5emF-RO5QvX"},"source":["# Detectando glaciares en imágenes de satélite con ViT"]},{"cell_type":"markdown","metadata":{"id":"zjU8MPbw5sc-"},"source":["## Librerías adicionales\n","\n","Librerías no incluidas en el entorno de Google Colab"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":4581,"status":"ok","timestamp":1675790525479,"user":{"displayName":"Carlos Germán Sellers Mendo","userId":"10483787242844398475"},"user_tz":-60},"id":"ntLGxCmh5voi"},"outputs":[],"source":["!pip install transformers[sentencepiece] datasets evaluate wandb -qqq"]},{"cell_type":"markdown","metadata":{"id":"Xe6lXLW45hMf"},"source":["# Imports y Constantes"]},{"cell_type":"markdown","metadata":{"id":"IaAVrghi5mpD"},"source":["## Imports"]},{"cell_type":"markdown","metadata":{"id":"Q4PH8tSBCDIu"},"source":["A continuación se hacen los import de los módulos y librerías en Python para un proyecto de procesamiento de imágenes y modelado de lenguaje.\n","  La línea from datasets import load_dataset, load_from_disk, DatasetDict importa funciones específicas del módulo datasets para cargar y trabajar con datasets.\n","  La línea import evaluate importa un módulo llamado evaluate que se utiliza para evaluar el rendimiento de un modelo.\n","  La línea import torch importa la librería PyTorch, que es una plataforma popular para el aprendizaje profundo y el procesamiento de imágenes.\n","  Las líneas from transformers import (ViTFeatureExtractor, ViTForImageClassification, TrainingArguments, Trainer, EarlyStoppingCallback, pipeline) importan componentes específicos de la librería Transformers relacionados con la extracción de características, la clasificación de imágenes, los argumentos de entrenamiento, el entrenador, el controlador de detención temprana y la tubería.\n","  La línea from transformers import set_seed importa una función para establecer la semilla de números aleatorios en la librería Transformers.\n","  La línea import numpy as np importa la librería NumPy, que es una librería de cálculo numérico popular en Python.\n","  La línea import wandb importa la librería Weights \u0026 Biases (W\u0026B), que es una plataforma de monitoreo y visualización de entrenamiento de modelos de aprendizaje automático."]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":5423,"status":"ok","timestamp":1675790530897,"user":{"displayName":"Carlos Germán Sellers Mendo","userId":"10483787242844398475"},"user_tz":-60},"id":"ZUKXH-VD5gUI"},"outputs":[],"source":["# datasets\n","from datasets import load_dataset, load_from_disk, DatasetDict\n","import evaluate\n","\n","# pytorch\n","import torch\n","\n","# transformers\n","from transformers import (\n","    ViTFeatureExtractor, ViTForImageClassification,\n","    TrainingArguments, Trainer, EarlyStoppingCallback,\n","    pipeline\n",")\n","from transformers import set_seed\n","# arrays\n","import numpy as np\n","\n","# wandb\n","import wandb"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":12,"status":"ok","timestamp":1675790530897,"user":{"displayName":"Carlos Germán Sellers Mendo","userId":"10483787242844398475"},"user_tz":-60},"id":"C8B3_LB8dEJ7"},"outputs":[],"source":["# fijar seed para inicializar pesos en la capa de clasificación siempre de la misma forma\n","set_seed(42)"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1305,"status":"ok","timestamp":1675790532191,"user":{"displayName":"Carlos Germán Sellers Mendo","userId":"10483787242844398475"},"user_tz":-60},"id":"eVo6HfK67v_3","outputId":"3fa03497-98d0-41fc-a1cb-50b0202f0878"},"outputs":[{"name":"stdout","output_type":"stream","text":["Tue Feb  7 17:22:03 2023       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 510.47.03    Driver Version: 510.47.03    CUDA Version: 11.6     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   40C    P0    15W /  70W |      0MiB / 15360MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["# check if there is GPU available\n","!nvidia-smi"]},{"cell_type":"markdown","metadata":{"id":"929xDejp8GPv"},"source":["### wandb login"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":0,"status":"ok","timestamp":1675790520529,"user":{"displayName":"Carlos Germán Sellers Mendo","userId":"10483787242844398475"},"user_tz":-60},"id":"snBX4LYI8ItJ","outputId":"2ecfa6e0-52f6-4950-f2cd-4b7bdae61e01"},"outputs":[{"name":"stderr","output_type":"stream","text":["ERROR:wandb.jupyter:Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcgsellersm01\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]},{"data":{"text/plain":["True"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["wandb.login()"]},{"cell_type":"markdown","metadata":{"id":"AQCH6Hm2-Gmh"},"source":["Con W\u0026B, podemos utilizar variables de entorno para ciertas cosas. En este caso:\n","- Nombre del notebook\n","- Proyecto\n","- Registrar modelo automáticamente como artefacto"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":49,"status":"ok","timestamp":1675790520530,"user":{"displayName":"Carlos Germán Sellers Mendo","userId":"10483787242844398475"},"user_tz":-60},"id":"DMPhQnYwK4Tr","outputId":"1214c541-3c0b-4e49-c63b-e3defb1bd6b8"},"outputs":[{"name":"stdout","output_type":"stream","text":["env: WANDB_NOTEBOOK_NAME=3_final_vit_glaciar_dataset_v2\n","env: WANDB_PROJECT=vit-clasificacion\n","env: WANDB_LOG_MODEL=true\n"]}],"source":["%env WANDB_NOTEBOOK_NAME=3_final_vit_glaciar_dataset_v2\n","#%env WANDB_PROJECT=NEW_vit-image-classification-glacier\n","%env WANDB_PROJECT=vit-clasificacion\n","# guardar modelo\n","%env WANDB_LOG_MODEL=true"]},{"cell_type":"markdown","metadata":{"id":"VCAlnKQA5nq0"},"source":["## Constantes"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":874,"status":"ok","timestamp":1675790521374,"user":{"displayName":"Carlos Germán Sellers Mendo","userId":"10483787242844398475"},"user_tz":-60},"id":"5VWgiXLx5ovI","outputId":"7cc19b2f-29bd-42d6-ebaa-072c9a8d6e76"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.8/dist-packages/transformers/models/vit/feature_extraction_vit.py:28: FutureWarning: The class ViTFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use ViTImageProcessor instead.\n","  warnings.warn(\n"]}],"source":["# dataset\n","HF_DATASET_IDENTIFIER = \"alkzar90/rock-glacier-dataset\"\n","HF_DATASET_CONFIG = \"image-classification\"\n","\n","# model path\n","HF_MODEL_PATH = \"google/vit-base-patch16-224-in21k\"\n","\n","# feature extractor from model checkpoint\n","FEATURE_EXTRACTOR = ViTFeatureExtractor.from_pretrained(HF_MODEL_PATH)\n","\n","# metrics\n","ACCURACY = evaluate.load(\"accuracy\")\n","FSCORE = evaluate.load(\"f1\")\n","\n","# early stopping\n","EARLY_STOPPING_CALLBACK = EarlyStoppingCallback(\n","    early_stopping_patience=5\n",")\n","\n","# wandb\n","#WANDB_PROJECT_NAME = \"NEW_vit-image-classification-glacier\"\n","WANDB_PROJECT_NAME = \"vit-clasificacion\"\n","#WANDB_TEAM = \"anban-dl\"\n","WANDB_TEAM = \"cgsellersm01\""]},{"cell_type":"markdown","metadata":{"id":"IC2V03Sk6BWI"},"source":["# Descargar los datos"]},{"cell_type":"markdown","metadata":{"id":"fuw463-m-izY"},"source":["## Registrar un tabla en W\u0026B para visualizar los datos"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":194},"executionInfo":{"elapsed":2970,"status":"ok","timestamp":1675790524226,"user":{"displayName":"Carlos Germán Sellers Mendo","userId":"10483787242844398475"},"user_tz":-60},"id":"MopY5031qn28","outputId":"c386364c-a08e-441c-dcd2-e12939ff38db"},"outputs":[{"data":{"text/html":["Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to \u003ca href=\"https://wandb.me/wandb-init\" target=\"_blank\"\u003ethe W\u0026B docs\u003c/a\u003e."],"text/plain":["\u003cIPython.core.display.HTML object\u003e"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Tracking run with wandb version 0.13.9"],"text/plain":["\u003cIPython.core.display.HTML object\u003e"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in \u003ccode\u003e/content/wandb/run-20230207_172207-6333cf49\u003c/code\u003e"],"text/plain":["\u003cIPython.core.display.HTML object\u003e"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run \u003cstrong\u003e\u003ca href=\"https://wandb.ai/cgsellersm01/vit-clasificacion/runs/6333cf49\" target=\"_blank\"\u003ewarm-plant-21\u003c/a\u003e\u003c/strong\u003e to \u003ca href=\"https://wandb.ai/cgsellersm01/vit-clasificacion\" target=\"_blank\"\u003eWeights \u0026 Biases\u003c/a\u003e (\u003ca href=\"https://wandb.me/run\" target=\"_blank\"\u003edocs\u003c/a\u003e)\u003cbr/\u003e"],"text/plain":["\u003cIPython.core.display.HTML object\u003e"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at \u003ca href=\"https://wandb.ai/cgsellersm01/vit-clasificacion\" target=\"_blank\"\u003ehttps://wandb.ai/cgsellersm01/vit-clasificacion\u003c/a\u003e"],"text/plain":["\u003cIPython.core.display.HTML object\u003e"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at \u003ca href=\"https://wandb.ai/cgsellersm01/vit-clasificacion/runs/6333cf49\" target=\"_blank\"\u003ehttps://wandb.ai/cgsellersm01/vit-clasificacion/runs/6333cf49\u003c/a\u003e"],"text/plain":["\u003cIPython.core.display.HTML object\u003e"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact raw_rock-glacier-dataset:v0, 312.26MB. 10 files... \n","\u001b[34m\u001b[1mwandb\u001b[0m:   10 of 10 files downloaded.  \n","Done. 0:0:0.1\n"]}],"source":["wandb.init(\n","    project=WANDB_PROJECT_NAME,\n","    entity=WANDB_TEAM,\n","    job_type=\"dataset-splits-logging\"\n",")\n","\n","# use artifact in wandb\n","# artifact name can be found in the artifact in W\u0026B\n","artifact = wandb.use_artifact(\n","    #\"anban-dl/NEW_vit-image-classification-glacier/raw_rock-glacier-dataset:v0\"\n","    \"cgsellersm01/vit-clasificacion/raw_rock-glacier-dataset:v0\"\n",")\n","artifact_dir = artifact.download()\n","raw_datasets = load_from_disk(artifact_dir)"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":43,"status":"ok","timestamp":1675790524856,"user":{"displayName":"Carlos Germán Sellers Mendo","userId":"10483787242844398475"},"user_tz":-60},"id":"T55YYWLnreHn","outputId":"41672859-06e0-4165-dc59-d504ee0c982d"},"outputs":[{"data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['image', 'labels', 'path'],\n","        num_rows: 7875\n","    })\n","    validation: Dataset({\n","        features: ['image', 'labels', 'path'],\n","        num_rows: 1125\n","    })\n","    test: Dataset({\n","        features: ['image', 'labels', 'path'],\n","        num_rows: 2700\n","    })\n","})"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["raw_datasets"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":21,"status":"ok","timestamp":1675790524857,"user":{"displayName":"Carlos Germán Sellers Mendo","userId":"10483787242844398475"},"user_tz":-60},"id":"SUNQjljhTz1Y"},"outputs":[],"source":["def create_train_val_table(dataset: DatasetDict) -\u003e wandb.data_types.Table:\n","    \"\"\"Create a table with data in W\u0026B for exploratory data analysis\"\"\"\n","    table = wandb.Table(columns=[\"path\", \"image\", \"split\", \"label\"])\n","\n","    for row in dataset[\"train\"]:\n","        table.add_data(\n","            str(row[\"path\"]),\n","            wandb.Image(row[\"image\"]),\n","            \"train\",\n","            row[\"labels\"]\n","        )\n","\n","    for row in dataset[\"validation\"]:\n","        table.add_data(\n","            str(row[\"path\"]),\n","            wandb.Image(row[\"image\"]),\n","            \"validation\",\n","            row[\"labels\"]\n","        )\n","\n","    return table"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":101095,"status":"ok","timestamp":1675790625932,"user":{"displayName":"Carlos Germán Sellers Mendo","userId":"10483787242844398475"},"user_tz":-60},"id":"1yCyhwb1Tf8j"},"outputs":[],"source":["# create table\n","table = create_train_val_table(raw_datasets)"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":443},"executionInfo":{"elapsed":13034,"status":"ok","timestamp":1675790638922,"user":{"displayName":"Carlos Germán Sellers Mendo","userId":"10483787242844398475"},"user_tz":-60},"id":"qLoAK7m9Tf56","outputId":"78c8a489-8b78-4371-e529-8f4514b2a77a"},"outputs":[{"data":{"text/html":["Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to \u003ca href=\"https://wandb.me/wandb-init\" target=\"_blank\"\u003ethe W\u0026B docs\u003c/a\u003e."],"text/plain":["\u003cIPython.core.display.HTML object\u003e"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Finishing last run (ID:6333cf49) before initializing another..."],"text/plain":["\u003cIPython.core.display.HTML object\u003e"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Waiting for W\u0026B process to finish... \u003cstrong style=\"color:green\"\u003e(success).\u003c/strong\u003e"],"text/plain":["\u003cIPython.core.display.HTML object\u003e"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4b8b6b26f9d646f8907cb0b19e7fb563","version_major":2,"version_minor":0},"text/plain":["VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run \u003cstrong style=\"color:#cdcd00\"\u003ewarm-plant-21\u003c/strong\u003e at: \u003ca href=\"https://wandb.ai/cgsellersm01/vit-clasificacion/runs/6333cf49\" target=\"_blank\"\u003ehttps://wandb.ai/cgsellersm01/vit-clasificacion/runs/6333cf49\u003c/a\u003e\u003cbr/\u003eSynced 5 W\u0026B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["\u003cIPython.core.display.HTML object\u003e"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: \u003ccode\u003e./wandb/run-20230207_172207-6333cf49/logs\u003c/code\u003e"],"text/plain":["\u003cIPython.core.display.HTML object\u003e"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Successfully finished last run (ID:6333cf49). Initializing new run:\u003cbr/\u003e"],"text/plain":["\u003cIPython.core.display.HTML object\u003e"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Tracking run with wandb version 0.13.9"],"text/plain":["\u003cIPython.core.display.HTML object\u003e"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in \u003ccode\u003e/content/wandb/run-20230207_172347-ia9w7dhk\u003c/code\u003e"],"text/plain":["\u003cIPython.core.display.HTML object\u003e"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run \u003cstrong\u003e\u003ca href=\"https://wandb.ai/cgsellersm01/vit-clasificacion/runs/ia9w7dhk\" target=\"_blank\"\u003eadd table\u003c/a\u003e\u003c/strong\u003e to \u003ca href=\"https://wandb.ai/cgsellersm01/vit-clasificacion\" target=\"_blank\"\u003eWeights \u0026 Biases\u003c/a\u003e (\u003ca href=\"https://wandb.me/run\" target=\"_blank\"\u003edocs\u003c/a\u003e)\u003cbr/\u003e"],"text/plain":["\u003cIPython.core.display.HTML object\u003e"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at \u003ca href=\"https://wandb.ai/cgsellersm01/vit-clasificacion\" target=\"_blank\"\u003ehttps://wandb.ai/cgsellersm01/vit-clasificacion\u003c/a\u003e"],"text/plain":["\u003cIPython.core.display.HTML object\u003e"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at \u003ca href=\"https://wandb.ai/cgsellersm01/vit-clasificacion/runs/ia9w7dhk\" target=\"_blank\"\u003ehttps://wandb.ai/cgsellersm01/vit-clasificacion/runs/ia9w7dhk\u003c/a\u003e"],"text/plain":["\u003cIPython.core.display.HTML object\u003e"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Waiting for W\u0026B process to finish... \u003cstrong style=\"color:green\"\u003e(success).\u003c/strong\u003e"],"text/plain":["\u003cIPython.core.display.HTML object\u003e"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3b6ae240abd04869b85fab9eb0c7313f","version_major":2,"version_minor":0},"text/plain":["VBox(children=(Label(value='0.001 MB of 0.009 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.082354…"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run \u003cstrong style=\"color:#cdcd00\"\u003eadd table\u003c/strong\u003e at: \u003ca href=\"https://wandb.ai/cgsellersm01/vit-clasificacion/runs/ia9w7dhk\" target=\"_blank\"\u003ehttps://wandb.ai/cgsellersm01/vit-clasificacion/runs/ia9w7dhk\u003c/a\u003e\u003cbr/\u003eSynced 4 W\u0026B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["\u003cIPython.core.display.HTML object\u003e"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: \u003ccode\u003e./wandb/run-20230207_172347-ia9w7dhk/logs\u003c/code\u003e"],"text/plain":["\u003cIPython.core.display.HTML object\u003e"]},"metadata":{},"output_type":"display_data"}],"source":["# start run and log table\n","run = wandb.init(\n","    project=WANDB_PROJECT_NAME,\n","    #entity=WANDB_TEAM,\n","    job_type=\"upload\",\n","    name=\"add table\",\n","    notes=\"add training and validation data table\"\n",")\n","train_val_data = wandb.Artifact(\"table_train_val_data\", type=\"table\")\n","train_val_data.add(table, \"train_val_data\")\n","run.log_artifact(train_val_data)\n","run.finish()"]},{"cell_type":"markdown","metadata":{"id":"e53s9ndb8ve9"},"source":["# Pre-procesado de los datos\n","\n","Utilizamos `ViTFeatureExtractor` para preprocesar los datos para ViT. Hugging Face lo tiene disponible en la librería `transformers`.\n","\n","**IMPORTANTE** - Recordad utilizar la misma version de feature extractor que el modelo que vais a utilizar (google/vit-base-patch16-224-in21k)\n"]},{"cell_type":"markdown","metadata":{"id":"eqZf1Nqw9wJX"},"source":["Configuración for defecto para ViT."]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18,"status":"ok","timestamp":1675790517010,"user":{"displayName":"Carlos Germán Sellers Mendo","userId":"10483787242844398475"},"user_tz":-60},"id":"9Is-rqpDLuQd","outputId":"799aa1ff-3cba-4958-ec47-f4d7a456a94a"},"outputs":[{"data":{"text/plain":["ViTFeatureExtractor {\n","  \"do_normalize\": true,\n","  \"do_rescale\": true,\n","  \"do_resize\": true,\n","  \"image_mean\": [\n","    0.5,\n","    0.5,\n","    0.5\n","  ],\n","  \"image_processor_type\": \"ViTFeatureExtractor\",\n","  \"image_std\": [\n","    0.5,\n","    0.5,\n","    0.5\n","  ],\n","  \"resample\": 2,\n","  \"rescale_factor\": 0.00392156862745098,\n","  \"size\": {\n","    \"height\": 224,\n","    \"width\": 224\n","  }\n","}"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["FEATURE_EXTRACTOR"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":30,"status":"ok","timestamp":1675790638923,"user":{"displayName":"Carlos Germán Sellers Mendo","userId":"10483787242844398475"},"user_tz":-60},"id":"4oSRVCpT9uAq"},"outputs":[],"source":["def transform(batch: dict) -\u003e dict:\n","  \"\"\"Transform images accoding to ViT requirements\"\"\"\n","  inputs = FEATURE_EXTRACTOR(\n","      [x.convert(\"RGB\") for x in batch[\"image\"]],\n","      return_tensors=\"pt\"\n","  )\n","  inputs[\"labels\"] = batch[\"labels\"]\n","  return inputs"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":28,"status":"ok","timestamp":1675790638923,"user":{"displayName":"Carlos Germán Sellers Mendo","userId":"10483787242844398475"},"user_tz":-60},"id":"HB6_9Vd9-dW-"},"outputs":[],"source":["# apply transformations to dataset\n","preprocessed_dataset = raw_datasets.with_transform(transform)"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":28,"status":"ok","timestamp":1675790638923,"user":{"displayName":"Carlos Germán Sellers Mendo","userId":"10483787242844398475"},"user_tz":-60},"id":"yktOk--_-5ms","outputId":"3350aad0-dea8-4303-eed4-05bcba931369"},"outputs":[{"data":{"text/plain":["{'pixel_values': tensor([[[-0.4431, -0.4431, -0.4431,  ..., -0.4118, -0.4039, -0.3961],\n","          [-0.4431, -0.4431, -0.4431,  ..., -0.4118, -0.4039, -0.3961],\n","          [-0.4353, -0.4353, -0.4431,  ..., -0.4039, -0.4039, -0.4039],\n","          ...,\n","          [-0.3020, -0.3020, -0.3098,  ..., -0.2627, -0.2549, -0.2471],\n","          [-0.3098, -0.3098, -0.3098,  ..., -0.2549, -0.2392, -0.2314],\n","          [-0.3098, -0.3098, -0.3098,  ..., -0.2471, -0.2314, -0.2235]],\n"," \n","         [[-0.5373, -0.5373, -0.5373,  ..., -0.5294, -0.5216, -0.5137],\n","          [-0.5294, -0.5373, -0.5373,  ..., -0.5294, -0.5216, -0.5137],\n","          [-0.5216, -0.5294, -0.5373,  ..., -0.5294, -0.5216, -0.5216],\n","          ...,\n","          [-0.4588, -0.4588, -0.4588,  ..., -0.4039, -0.3961, -0.3961],\n","          [-0.4588, -0.4588, -0.4588,  ..., -0.3961, -0.3882, -0.3882],\n","          [-0.4588, -0.4588, -0.4588,  ..., -0.3961, -0.3882, -0.3882]],\n"," \n","         [[-0.5765, -0.5765, -0.5843,  ..., -0.5922, -0.5843, -0.5765],\n","          [-0.5765, -0.5765, -0.5843,  ..., -0.5922, -0.5843, -0.5765],\n","          [-0.5765, -0.5765, -0.5765,  ..., -0.5922, -0.5843, -0.5843],\n","          ...,\n","          [-0.5451, -0.5451, -0.5451,  ..., -0.4980, -0.4902, -0.4902],\n","          [-0.5373, -0.5373, -0.5451,  ..., -0.4980, -0.4902, -0.4902],\n","          [-0.5373, -0.5373, -0.5451,  ..., -0.4980, -0.4902, -0.4902]]]),\n"," 'labels': 0}"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["# check\n","preprocessed_dataset[\"train\"][0]"]},{"cell_type":"markdown","metadata":{"id":"lSDniU6e5o4E"},"source":["# Entrenamiento y evaluación"]},{"cell_type":"markdown","metadata":{"id":"qVMZL5g34U3T"},"source":["## Utils\n","\n","Funciones de utilidad que utilizaremos durante el entrenamiento.\n","   \"collate_fn\" toma como entrada un diccionario llamado \"batch\" y devuelve otro diccionario con dos claves: \"pixel_values\" y \"labels\". \"pixel_values\" es una pila (stack) de tensores de Torch formados por los valores de los pixeles de los elementos en \"batch\". \"labels\" es un tensor de Torch que contiene las etiquetas correspondientes a cada elemento en \"batch\".\n","\n","   \"compute_metrics\" toma como entrada un objeto \"preds\" y devuelve un diccionario con dos claves: \"accuracy\" y \"f1\". \"accuracy\" es el valor de la precisión calculada mediante la función \"ACCURACY.compute\" y \"f1\" es el valor del F1 Score calculado mediante la función \"FSCORE.compute\". La precisión y el F1 Score se calculan comparando los índices de la clase más probable (calculados por np.argmax en \"preds.predictions\", eje=1) con las etiquetas reales (en \"preds.label_ids\")."]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":454,"status":"ok","timestamp":1675790639350,"user":{"displayName":"Carlos Germán Sellers Mendo","userId":"10483787242844398475"},"user_tz":-60},"id":"sU4kAoGJ1Whk"},"outputs":[],"source":["def collate_fn(batch: dict) -\u003e dict:\n","    \"\"\"Function that processes a batch\"\"\"\n","    return {\n","        'pixel_values': torch.stack([torch.Tensor(x['pixel_values']) for x in batch]),\n","        'labels': torch.tensor([x['labels'] for x in batch])\n","    }\n","\n","\n","def compute_metrics(preds) -\u003e dict:\n","    \"\"\"Compute accuracy and f1 score\"\"\"\n","    accuracy = ACCURACY.compute(\n","        predictions=np.argmax(preds.predictions, axis=1),\n","        references=preds.label_ids\n","    )\n","    f_score = FSCORE.compute(\n","        predictions=np.argmax(preds.predictions, axis=1),\n","        references=preds.label_ids\n","    )\n","    return {\n","        \"accuracy\": accuracy,\n","        \"f1\": f_score\n","    }"]},{"cell_type":"markdown","metadata":{"id":"zjYa2lkD5tjS"},"source":["## Fine-tune\n","\n","Función para el entrenamiento\n","Toma como entrada una tabla de WandB, un diccionario de datos llamado \"dataset\", dos arrays de Numpy llamados \"probs\" y \"preds\", y una cadena \"split\". La función agrega información a la tabla de resumen, que luego se registrará en W\u0026B.\n","\n","Por cada fila en el diccionario \"dataset[split]\", la función extrae la ruta del archivo, la imagen, la etiqueta y las probabilidades y predicción correspondientes. Luego, la información se agrega a la tabla con el método \"table.add_data\". La información agregada incluye la ruta, la imagen, la etiqueta, la predicción y las probabilidades."]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":33,"status":"ok","timestamp":1675790639350,"user":{"displayName":"Carlos Germán Sellers Mendo","userId":"10483787242844398475"},"user_tz":-60},"id":"ghOEpkApl0Sg"},"outputs":[],"source":["def add_to_summary_table(\n","    table: wandb.data_types.Table,\n","    dataset: DatasetDict,\n","    probs: np.array,\n","    preds: np.array,\n","    split: str\n",") -\u003e None:\n","    \"\"\"Create a summary table with predictions and labels to be logged to W\u0026B\"\"\"\n","    for row_dict, probs, pred in zip(dataset[split], probs, preds):\n","        path = str(row_dict[\"path\"])\n","        image = wandb.Image(row_dict[\"image\"])\n","        label = row_dict[\"labels\"]\n","        # add to table\n","        table.add_data(path, image, split, label, pred, probs)"]},{"cell_type":"markdown","metadata":{"id":"PV6y0ac9Els8"},"source":["A continuación, la función llamada \"fine_tune\" que realiza un ajuste fino en un modelo de clasificación de imágenes basado en el modelo ViT y evalúa el resultado en un conjunto de validación. La función recibe cuatro argumentos: \"run_name\", \"run_notes\", \"tags\" y \"config\". El objetivo final es entrenar un modelo y registrar los resultados en W\u0026B (Weights \u0026 Biases).\n","\n","La función inicializa una nueva ejecución (run) en W\u0026B, descarga los conjuntos de datos necesarios y crea un modelo ViT con etiquetas específicas. Luego, se definen los argumentos de entrenamiento y se inicializa un entrenador con el modelo, los argumentos de entrenamiento y los datos preprocesados. Finalmente, se entrena el modelo y se registran las predicciones en los conjuntos de datos de entrenamiento y validación en W\u0026B a través de una tabla resumen"]},{"cell_type":"code","execution_count":20,"metadata":{"executionInfo":{"elapsed":501,"status":"ok","timestamp":1675790729773,"user":{"displayName":"Carlos Germán Sellers Mendo","userId":"10483787242844398475"},"user_tz":-60},"id":"4sDKbGF42F2_"},"outputs":[],"source":["def fine_tune(\n","    run_name: str,\n","    run_notes: str,\n","    tags: list,\n","    config: dict\n",") -\u003e Trainer:\n","    \"\"\"\n","    Fine-tune ViT and evaluate on validation set.\n","    Log fine-tune and model to W\u0026B.\n","    \"\"\"\n","    # initialize new run\n","    with wandb.init(\n","        project=WANDB_PROJECT_NAME,\n","        name=run_name,\n","        notes=run_notes,\n","        tags=tags\n","    ) as run:\n","\n","        # download dataset from W\u0026B\n","        #dataset = run.use_artifact(\"anban-dl/vit-image-classification-glacier/raw_rock-glacier-dataset:v0\")\n","        dataset = run.use_artifact(\"cgsellersm01/vit-clasificacion/raw_rock-glacier-dataset:v0\")\n","        data_dir = dataset.download()\n","        dataset = load_from_disk(data_dir)\n","        # extract label names\n","        labels = dataset['train'].features['labels'].names\n","\n","        # download preprocessed datasets\n","        preprocessed_dataset = dict()\n","        for split in [\"train\", \"validation\"]:\n","            #split_dataset = run.use_artifact(f\"anban-dl/vit-image-classification-glacier/{split}_preprocessed:v0\")\n","            split_dataset = run.use_artifact(f\"cgsellersm01/vit-clasificacion/{split}_preprocessed:v0\")\n","            data_dir = split_dataset.download()\n","            split_dataset = load_from_disk(data_dir)\n","            preprocessed_dataset[split] = split_dataset\n","\n","        # create model\n","        model = ViTForImageClassification.from_pretrained(\n","            HF_MODEL_PATH,\n","            num_labels=len(labels),\n","            id2label={str(i): c for i, c in enumerate(labels)},\n","            label2id={c: str(i) for i, c in enumerate(labels)}\n","        )\n","\n","        # arguments\n","        training_args = TrainingArguments(\n","            output_dir=\"./vit-base-demo\",\n","            per_device_train_batch_size=config[\"per_device_train_batch_size\"], # IMP entrenamiento\n","            per_device_eval_batch_size=config[\"per_device_eval_batch_size\"], # IMP entrenamiento\n","            save_strategy=\"steps\",\n","            evaluation_strategy=\"steps\",\n","            save_steps=50,\n","            eval_steps=50,\n","            num_train_epochs=config[\"num_train_epochs\"], # IMP entrenamiento\n","            fp16=True,\n","            logging_strategy=\"steps\",\n","            logging_steps=50,\n","            learning_rate=config[\"learning_rate\"], # IMP entrenamiento\n","            weight_decay=config[\"weight_decay\"], # IMP entrenamiento\n","            save_total_limit=2,\n","            remove_unused_columns=False,\n","            push_to_hub=False,\n","            load_best_model_at_end=True,\n","            report_to=\"wandb\"\n","        )\n","\n","        # default optim is AdamW\n","        trainer = Trainer(\n","            model=model,\n","            args=training_args,\n","            data_collator=collate_fn,\n","            compute_metrics=compute_metrics,\n","            train_dataset=preprocessed_dataset[\"train\"],\n","            eval_dataset=preprocessed_dataset[\"validation\"],\n","            tokenizer=FEATURE_EXTRACTOR,\n","            callbacks=[EARLY_STOPPING_CALLBACK]\n","        )\n","\n","        # train\n","        trainer.train()\n","\n","        # log predictions on train set and validation set\n","        train_probs= trainer.predict(\n","            preprocessed_dataset[\"train\"]\n","        ).predictions\n","        train_preds = np.argmax(train_probs, axis=1)\n","\n","        val_probs = trainer.predict(\n","            preprocessed_dataset[\"validation\"]\n","        ).predictions\n","        val_preds = np.argmax(val_probs, axis=1)\n","\n","        # summary table\n","        table = wandb.Table(\n","            columns=[\"path\", \"image\", \"split\", \"label\", \"prediction\", \"probs\"]\n","        )\n","        \n","        # add train data\n","        add_to_summary_table(\n","            table,\n","            dataset,\n","            train_probs,\n","            train_preds,\n","            \"train\"\n","        )\n","        # add val data\n","        add_to_summary_table(\n","            table,\n","            dataset,\n","            val_probs,\n","            val_preds,\n","            \"validation\"\n","        )\n","\n","        run.log({\"summary_table\": table})\n","        run.finish()\n","\n","        return trainer"]},{"cell_type":"markdown","metadata":{"id":"VbP9dxecfEZA"},"source":["## Realizar un experimento\n","Se establecen tres variables: \"run_name\", \"run_notes\" y \"tags\". La variable \"run_name\" es un nombre de corrida (ejecución), \"run_notes\" es una nota o descripción del experimento y \"tags\" es una lista de etiquetas asociadas al experimento.\n","\n","Luego, se definen los parámetros de entrenamiento en un diccionario llamado \"config\". Estos incluyen el tamaño del lote por dispositivo durante el entrenamiento y la evaluación, el número de épocas de entrenamiento, la tasa de aprendizaje y la tasa de decadencia del peso.\n","\n","Finalmente, se llama a una función llamada \"fine_tune\" para realizar el ajuste fino. Se le pasan las tres variables establecidas anteriormente y el diccionario de configuración como argumentos."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":1000},"id":"svB2_MxpAh-h"},"outputs":[{"data":{"text/html":["Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to \u003ca href=\"https://wandb.me/wandb-init\" target=\"_blank\"\u003ethe W\u0026B docs\u003c/a\u003e."],"text/plain":["\u003cIPython.core.display.HTML object\u003e"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"63bd54cd383046bd8a52a6d937df7b22","version_major":2,"version_minor":0},"text/plain":["VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01666885668333483, max=1.0)…"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Tracking run with wandb version 0.13.9"],"text/plain":["\u003cIPython.core.display.HTML object\u003e"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in \u003ccode\u003e/content/wandb/run-20230207_172535-bv8olag7\u003c/code\u003e"],"text/plain":["\u003cIPython.core.display.HTML object\u003e"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run \u003cstrong\u003e\u003ca href=\"https://wandb.ai/cgsellersm01/vit-clasificacion/runs/bv8olag7\" target=\"_blank\"\u003ebaseline\u003c/a\u003e\u003c/strong\u003e to \u003ca href=\"https://wandb.ai/cgsellersm01/vit-clasificacion\" target=\"_blank\"\u003eWeights \u0026 Biases\u003c/a\u003e (\u003ca href=\"https://wandb.me/run\" target=\"_blank\"\u003edocs\u003c/a\u003e)\u003cbr/\u003e"],"text/plain":["\u003cIPython.core.display.HTML object\u003e"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at \u003ca href=\"https://wandb.ai/cgsellersm01/vit-clasificacion\" target=\"_blank\"\u003ehttps://wandb.ai/cgsellersm01/vit-clasificacion\u003c/a\u003e"],"text/plain":["\u003cIPython.core.display.HTML object\u003e"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at \u003ca href=\"https://wandb.ai/cgsellersm01/vit-clasificacion/runs/bv8olag7\" target=\"_blank\"\u003ehttps://wandb.ai/cgsellersm01/vit-clasificacion/runs/bv8olag7\u003c/a\u003e"],"text/plain":["\u003cIPython.core.display.HTML object\u003e"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact raw_rock-glacier-dataset:v0, 312.26MB. 10 files... \n","\u001b[34m\u001b[1mwandb\u001b[0m:   10 of 10 files downloaded.  \n","Done. 0:0:0.0\n","\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact train_preprocessed:v0, 4747.14MB. 12 files... \n","\u001b[34m\u001b[1mwandb\u001b[0m:   12 of 12 files downloaded.  \n","Done. 0:0:48.7\n","\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact validation_preprocessed:v0, 677.78MB. 4 files... \n","\u001b[34m\u001b[1mwandb\u001b[0m:   4 of 4 files downloaded.  \n","Done. 0:0:6.3\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"cf41d8a3a7bc4023adecbe9833257d1e","version_major":2,"version_minor":0},"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/502 [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"630646821a574913812363d14aa83749","version_major":2,"version_minor":0},"text/plain":["Downloading (…)\"pytorch_model.bin\";:   0%|          | 0.00/346M [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at google/vit-base-patch16-224-in21k were not used when initializing ViTForImageClassification: ['pooler.dense.bias', 'pooler.dense.weight']\n","- This IS expected if you are initializing ViTForImageClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing ViTForImageClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Setting `WANDB_LOG_MODEL` from true to `end` instead\n","Using cuda_amp half precision backend\n","/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","***** Running training *****\n","  Num examples = 7875\n","  Num Epochs = 3\n","  Instantaneous batch size per device = 32\n","  Total train batch size (w. parallel, distributed \u0026 accumulation) = 32\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 741\n","  Number of trainable parameters = 85800194\n","Automatic Weights \u0026 Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"]},{"data":{"text/html":["\n","    \u003cdiv\u003e\n","      \n","      \u003cprogress value='741' max='741' style='width:300px; height:20px; vertical-align: middle;'\u003e\u003c/progress\u003e\n","      [741/741 57:25, Epoch 3/3]\n","    \u003c/div\u003e\n","    \u003ctable border=\"1\" class=\"dataframe\"\u003e\n","  \u003cthead\u003e\n"," \u003ctr style=\"text-align: left;\"\u003e\n","      \u003cth\u003eStep\u003c/th\u003e\n","      \u003cth\u003eTraining Loss\u003c/th\u003e\n","      \u003cth\u003eValidation Loss\u003c/th\u003e\n","      \u003cth\u003eAccuracy\u003c/th\u003e\n","      \u003cth\u003eF1\u003c/th\u003e\n","    \u003c/tr\u003e\n","  \u003c/thead\u003e\n","  \u003ctbody\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e50\u003c/td\u003e\n","      \u003ctd\u003e0.470700\u003c/td\u003e\n","      \u003ctd\u003e0.337021\u003c/td\u003e\n","      \u003ctd\u003e{'accuracy': 0.8853333333333333}\u003c/td\u003e\n","      \u003ctd\u003e{'f1': 0.8577728776185226}\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e100\u003c/td\u003e\n","      \u003ctd\u003e0.274700\u003c/td\u003e\n","      \u003ctd\u003e0.223051\u003c/td\u003e\n","      \u003ctd\u003e{'accuracy': 0.9191111111111111}\u003c/td\u003e\n","      \u003ctd\u003e{'f1': 0.9132507149666349}\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e150\u003c/td\u003e\n","      \u003ctd\u003e0.217200\u003c/td\u003e\n","      \u003ctd\u003e0.175713\u003c/td\u003e\n","      \u003ctd\u003e{'accuracy': 0.9342222222222222}\u003c/td\u003e\n","      \u003ctd\u003e{'f1': 0.9273084479371315}\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e200\u003c/td\u003e\n","      \u003ctd\u003e0.152800\u003c/td\u003e\n","      \u003ctd\u003e0.210809\u003c/td\u003e\n","      \u003ctd\u003e{'accuracy': 0.9182222222222223}\u003c/td\u003e\n","      \u003ctd\u003e{'f1': 0.9008620689655173}\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e250\u003c/td\u003e\n","      \u003ctd\u003e0.149400\u003c/td\u003e\n","      \u003ctd\u003e0.155684\u003c/td\u003e\n","      \u003ctd\u003e{'accuracy': 0.9493333333333334}\u003c/td\u003e\n","      \u003ctd\u003e{'f1': 0.9400630914826499}\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e300\u003c/td\u003e\n","      \u003ctd\u003e0.079700\u003c/td\u003e\n","      \u003ctd\u003e0.108452\u003c/td\u003e\n","      \u003ctd\u003e{'accuracy': 0.9653333333333334}\u003c/td\u003e\n","      \u003ctd\u003e{'f1': 0.9608040201005025}\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e350\u003c/td\u003e\n","      \u003ctd\u003e0.079500\u003c/td\u003e\n","      \u003ctd\u003e0.103136\u003c/td\u003e\n","      \u003ctd\u003e{'accuracy': 0.9671111111111111}\u003c/td\u003e\n","      \u003ctd\u003e{'f1': 0.9629629629629629}\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e400\u003c/td\u003e\n","      \u003ctd\u003e0.062300\u003c/td\u003e\n","      \u003ctd\u003e0.094375\u003c/td\u003e\n","      \u003ctd\u003e{'accuracy': 0.9706666666666667}\u003c/td\u003e\n","      \u003ctd\u003e{'f1': 0.9672943508424183}\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e450\u003c/td\u003e\n","      \u003ctd\u003e0.062300\u003c/td\u003e\n","      \u003ctd\u003e0.087944\u003c/td\u003e\n","      \u003ctd\u003e{'accuracy': 0.9733333333333334}\u003c/td\u003e\n","      \u003ctd\u003e{'f1': 0.9698189134808852}\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e500\u003c/td\u003e\n","      \u003ctd\u003e0.038400\u003c/td\u003e\n","      \u003ctd\u003e0.101507\u003c/td\u003e\n","      \u003ctd\u003e{'accuracy': 0.9724444444444444}\u003c/td\u003e\n","      \u003ctd\u003e{'f1': 0.9687814702920443}\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e550\u003c/td\u003e\n","      \u003ctd\u003e0.030600\u003c/td\u003e\n","      \u003ctd\u003e0.099537\u003c/td\u003e\n","      \u003ctd\u003e{'accuracy': 0.9706666666666667}\u003c/td\u003e\n","      \u003ctd\u003e{'f1': 0.9664974619289339}\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e600\u003c/td\u003e\n","      \u003ctd\u003e0.017600\u003c/td\u003e\n","      \u003ctd\u003e0.110594\u003c/td\u003e\n","      \u003ctd\u003e{'accuracy': 0.9715555555555555}\u003c/td\u003e\n","      \u003ctd\u003e{'f1': 0.9673469387755103}\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e650\u003c/td\u003e\n","      \u003ctd\u003e0.026600\u003c/td\u003e\n","      \u003ctd\u003e0.100210\u003c/td\u003e\n","      \u003ctd\u003e{'accuracy': 0.9724444444444444}\u003c/td\u003e\n","      \u003ctd\u003e{'f1': 0.9685279187817258}\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e700\u003c/td\u003e\n","      \u003ctd\u003e0.017400\u003c/td\u003e\n","      \u003ctd\u003e0.080500\u003c/td\u003e\n","      \u003ctd\u003e{'accuracy': 0.9715555555555555}\u003c/td\u003e\n","      \u003ctd\u003e{'f1': 0.9678714859437753}\u003c/td\u003e\n","    \u003c/tr\u003e\n","  \u003c/tbody\u003e\n","\u003c/table\u003e\u003cp\u003e"],"text/plain":["\u003cIPython.core.display.HTML object\u003e"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["***** Running Evaluation *****\n","  Num examples = 1125\n","  Batch size = 16\n","Saving model checkpoint to ./vit-base-demo/checkpoint-50\n","Configuration saved in ./vit-base-demo/checkpoint-50/config.json\n","Model weights saved in ./vit-base-demo/checkpoint-50/pytorch_model.bin\n","Image processor saved in ./vit-base-demo/checkpoint-50/preprocessor_config.json\n","***** Running Evaluation *****\n","  Num examples = 1125\n","  Batch size = 16\n","Saving model checkpoint to ./vit-base-demo/checkpoint-100\n","Configuration saved in ./vit-base-demo/checkpoint-100/config.json\n","Model weights saved in ./vit-base-demo/checkpoint-100/pytorch_model.bin\n","Image processor saved in ./vit-base-demo/checkpoint-100/preprocessor_config.json\n","***** Running Evaluation *****\n","  Num examples = 1125\n","  Batch size = 16\n","Saving model checkpoint to ./vit-base-demo/checkpoint-150\n","Configuration saved in ./vit-base-demo/checkpoint-150/config.json\n","Model weights saved in ./vit-base-demo/checkpoint-150/pytorch_model.bin\n","Image processor saved in ./vit-base-demo/checkpoint-150/preprocessor_config.json\n","Deleting older checkpoint [vit-base-demo/checkpoint-50] due to args.save_total_limit\n","***** Running Evaluation *****\n","  Num examples = 1125\n","  Batch size = 16\n","Saving model checkpoint to ./vit-base-demo/checkpoint-200\n","Configuration saved in ./vit-base-demo/checkpoint-200/config.json\n","Model weights saved in ./vit-base-demo/checkpoint-200/pytorch_model.bin\n","Image processor saved in ./vit-base-demo/checkpoint-200/preprocessor_config.json\n","Deleting older checkpoint [vit-base-demo/checkpoint-100] due to args.save_total_limit\n","***** Running Evaluation *****\n","  Num examples = 1125\n","  Batch size = 16\n","Saving model checkpoint to ./vit-base-demo/checkpoint-250\n","Configuration saved in ./vit-base-demo/checkpoint-250/config.json\n","Model weights saved in ./vit-base-demo/checkpoint-250/pytorch_model.bin\n","Image processor saved in ./vit-base-demo/checkpoint-250/preprocessor_config.json\n","Deleting older checkpoint [vit-base-demo/checkpoint-150] due to args.save_total_limit\n","***** Running Evaluation *****\n","  Num examples = 1125\n","  Batch size = 16\n","Saving model checkpoint to ./vit-base-demo/checkpoint-300\n","Configuration saved in ./vit-base-demo/checkpoint-300/config.json\n","Model weights saved in ./vit-base-demo/checkpoint-300/pytorch_model.bin\n","Image processor saved in ./vit-base-demo/checkpoint-300/preprocessor_config.json\n","Deleting older checkpoint [vit-base-demo/checkpoint-200] due to args.save_total_limit\n","***** Running Evaluation *****\n","  Num examples = 1125\n","  Batch size = 16\n","Saving model checkpoint to ./vit-base-demo/checkpoint-350\n","Configuration saved in ./vit-base-demo/checkpoint-350/config.json\n","Model weights saved in ./vit-base-demo/checkpoint-350/pytorch_model.bin\n","Image processor saved in ./vit-base-demo/checkpoint-350/preprocessor_config.json\n","Deleting older checkpoint [vit-base-demo/checkpoint-250] due to args.save_total_limit\n","***** Running Evaluation *****\n","  Num examples = 1125\n","  Batch size = 16\n","Saving model checkpoint to ./vit-base-demo/checkpoint-400\n","Configuration saved in ./vit-base-demo/checkpoint-400/config.json\n","Model weights saved in ./vit-base-demo/checkpoint-400/pytorch_model.bin\n","Image processor saved in ./vit-base-demo/checkpoint-400/preprocessor_config.json\n","Deleting older checkpoint [vit-base-demo/checkpoint-300] due to args.save_total_limit\n","***** Running Evaluation *****\n","  Num examples = 1125\n","  Batch size = 16\n","Saving model checkpoint to ./vit-base-demo/checkpoint-450\n","Configuration saved in ./vit-base-demo/checkpoint-450/config.json\n","Model weights saved in ./vit-base-demo/checkpoint-450/pytorch_model.bin\n","Image processor saved in ./vit-base-demo/checkpoint-450/preprocessor_config.json\n","Deleting older checkpoint [vit-base-demo/checkpoint-350] due to args.save_total_limit\n","***** Running Evaluation *****\n","  Num examples = 1125\n","  Batch size = 16\n","Saving model checkpoint to ./vit-base-demo/checkpoint-500\n","Configuration saved in ./vit-base-demo/checkpoint-500/config.json\n","Model weights saved in ./vit-base-demo/checkpoint-500/pytorch_model.bin\n","Image processor saved in ./vit-base-demo/checkpoint-500/preprocessor_config.json\n","Deleting older checkpoint [vit-base-demo/checkpoint-400] due to args.save_total_limit\n","***** Running Evaluation *****\n","  Num examples = 1125\n","  Batch size = 16\n","Saving model checkpoint to ./vit-base-demo/checkpoint-550\n","Configuration saved in ./vit-base-demo/checkpoint-550/config.json\n","Model weights saved in ./vit-base-demo/checkpoint-550/pytorch_model.bin\n","Image processor saved in ./vit-base-demo/checkpoint-550/preprocessor_config.json\n","Deleting older checkpoint [vit-base-demo/checkpoint-500] due to args.save_total_limit\n","***** Running Evaluation *****\n","  Num examples = 1125\n","  Batch size = 16\n","Saving model checkpoint to ./vit-base-demo/checkpoint-600\n","Configuration saved in ./vit-base-demo/checkpoint-600/config.json\n","Model weights saved in ./vit-base-demo/checkpoint-600/pytorch_model.bin\n","Image processor saved in ./vit-base-demo/checkpoint-600/preprocessor_config.json\n","Deleting older checkpoint [vit-base-demo/checkpoint-550] due to args.save_total_limit\n","***** Running Evaluation *****\n","  Num examples = 1125\n","  Batch size = 16\n","Saving model checkpoint to ./vit-base-demo/checkpoint-650\n","Configuration saved in ./vit-base-demo/checkpoint-650/config.json\n","Model weights saved in ./vit-base-demo/checkpoint-650/pytorch_model.bin\n","Image processor saved in ./vit-base-demo/checkpoint-650/preprocessor_config.json\n","Deleting older checkpoint [vit-base-demo/checkpoint-600] due to args.save_total_limit\n","***** Running Evaluation *****\n","  Num examples = 1125\n","  Batch size = 16\n","Saving model checkpoint to ./vit-base-demo/checkpoint-700\n","Configuration saved in ./vit-base-demo/checkpoint-700/config.json\n","Model weights saved in ./vit-base-demo/checkpoint-700/pytorch_model.bin\n","Image processor saved in ./vit-base-demo/checkpoint-700/preprocessor_config.json\n","Deleting older checkpoint [vit-base-demo/checkpoint-450] due to args.save_total_limit\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","Loading best model from ./vit-base-demo/checkpoint-700 (score: 0.08049952983856201).\n","Setting `WANDB_LOG_MODEL` from true to `end` instead\n","Using cuda_amp half precision backend\n","Saving model checkpoint to /tmp/tmpl1xobp65\n","Configuration saved in /tmp/tmpl1xobp65/config.json\n","Model weights saved in /tmp/tmpl1xobp65/pytorch_model.bin\n","Image processor saved in /tmp/tmpl1xobp65/preprocessor_config.json\n","Logging model artifacts. ...\n","***** Running Prediction *****\n","  Num examples = 7875\n","  Batch size = 16\n"]},{"data":{"text/html":[],"text/plain":["\u003cIPython.core.display.HTML object\u003e"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["***** Running Prediction *****\n","  Num examples = 1125\n","  Batch size = 16\n"]},{"data":{"text/html":[],"text/plain":["\u003cIPython.core.display.HTML object\u003e"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Waiting for W\u0026B process to finish... \u003cstrong style=\"color:green\"\u003e(success).\u003c/strong\u003e"],"text/plain":["\u003cIPython.core.display.HTML object\u003e"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["\u003cstyle\u003e\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    \u003c/style\u003e\n","\u003cdiv class=\"wandb-row\"\u003e\u003cdiv class=\"wandb-col\"\u003e\u003ch3\u003eRun history:\u003c/h3\u003e\u003cbr/\u003e\u003ctable class=\"wandb\"\u003e\u003ctr\u003e\u003ctd\u003eeval/loss\u003c/td\u003e\u003ctd\u003e█▅▄▅▃▂▂▁▁▂▂▂▂▁\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003eeval/runtime\u003c/td\u003e\u003ctd\u003e█▂▁▂▆▄▆▆▄▂▅▅▇▁\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003eeval/samples_per_second\u003c/td\u003e\u003ctd\u003e▁▇█▇▃▅▃▃▅▇▄▄▂▇\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003eeval/steps_per_second\u003c/td\u003e\u003ctd\u003e▁▇█▇▃▄▃▃▅▇▄▄▂▇\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003etrain/epoch\u003c/td\u003e\u003ctd\u003e▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇███\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003etrain/global_step\u003c/td\u003e\u003ctd\u003e▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇████\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003etrain/learning_rate\u003c/td\u003e\u003ctd\u003e█▇▇▆▆▅▅▄▄▃▃▂▂▁\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003etrain/loss\u003c/td\u003e\u003ctd\u003e█▅▄▃▃▂▂▂▂▁▁▁▁▁\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003etrain/total_flos\u003c/td\u003e\u003ctd\u003e▁\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003etrain/train_loss\u003c/td\u003e\u003ctd\u003e▁\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003etrain/train_runtime\u003c/td\u003e\u003ctd\u003e▁\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003etrain/train_samples_per_second\u003c/td\u003e\u003ctd\u003e▁\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003etrain/train_steps_per_second\u003c/td\u003e\u003ctd\u003e▁\u003c/td\u003e\u003c/tr\u003e\u003c/table\u003e\u003cbr/\u003e\u003c/div\u003e\u003cdiv class=\"wandb-col\"\u003e\u003ch3\u003eRun summary:\u003c/h3\u003e\u003cbr/\u003e\u003ctable class=\"wandb\"\u003e\u003ctr\u003e\u003ctd\u003eeval/loss\u003c/td\u003e\u003ctd\u003e0.0805\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003eeval/runtime\u003c/td\u003e\u003ctd\u003e85.5029\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003eeval/samples_per_second\u003c/td\u003e\u003ctd\u003e13.157\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003eeval/steps_per_second\u003c/td\u003e\u003ctd\u003e0.83\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003etrain/epoch\u003c/td\u003e\u003ctd\u003e3.0\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003etrain/global_step\u003c/td\u003e\u003ctd\u003e741\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003etrain/learning_rate\u003c/td\u003e\u003ctd\u003e0.0\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003etrain/loss\u003c/td\u003e\u003ctd\u003e0.0174\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003etrain/total_flos\u003c/td\u003e\u003ctd\u003e1.830748254644736e+18\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003etrain/train_loss\u003c/td\u003e\u003ctd\u003e0.11443\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003etrain/train_runtime\u003c/td\u003e\u003ctd\u003e3449.3397\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003etrain/train_samples_per_second\u003c/td\u003e\u003ctd\u003e6.849\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003etrain/train_steps_per_second\u003c/td\u003e\u003ctd\u003e0.215\u003c/td\u003e\u003c/tr\u003e\u003c/table\u003e\u003cbr/\u003e\u003c/div\u003e\u003c/div\u003e"],"text/plain":["\u003cIPython.core.display.HTML object\u003e"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run \u003cstrong style=\"color:#cdcd00\"\u003ebaseline\u003c/strong\u003e at: \u003ca href=\"https://wandb.ai/cgsellersm01/vit-clasificacion/runs/bv8olag7\" target=\"_blank\"\u003ehttps://wandb.ai/cgsellersm01/vit-clasificacion/runs/bv8olag7\u003c/a\u003e\u003cbr/\u003eSynced 5 W\u0026B file(s), 1 media file(s), 9005 artifact file(s) and 0 other file(s)"],"text/plain":["\u003cIPython.core.display.HTML object\u003e"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: \u003ccode\u003e./wandb/run-20230207_172535-bv8olag7/logs\u003c/code\u003e"],"text/plain":["\u003cIPython.core.display.HTML object\u003e"]},"metadata":{},"output_type":"display_data"}],"source":["# experiment\n","run_name = \"baseline\"\n","run_notes = \"primer experimento\"\n","tags = [\"baseline\"]\n","\n","# parámetros a definir para el entrenamiento\n","config = {\n","    \"per_device_train_batch_size\": 32,\n","    \"per_device_eval_batch_size\": 16,\n","    \"num_train_epochs\": 3,\n","    \"learning_rate\": 3e-5, # 0.001, 0.01\n","    \"weight_decay\": 0\n","}\n","\n","# fine-tuning\n","trainer = fine_tune(\n","    run_name,\n","    run_notes,\n","    tags,\n","    config\n",")"]},{"cell_type":"markdown","metadata":{"id":"3x_PNzETfif1"},"source":["# Evaluation on test set\n","Este código define dos funciones en Python:\n","  **transform_test**(batch: dict) -\u003e dict: esta función toma como entrada un diccionario llamado \"batch\" que contiene imágenes y las transforma según los requisitos de ViT. Utiliza un extractor de características (FEATURE_EXTRACTOR) para convertir las imágenes en formato RGB y devuelve los tensores en formato PyTorch.\n","\n","  **compute_metrics_inference**(preds: list, labels: list) -\u003e dict: esta función toma como entrada dos listas \"preds\" y \"labels\" que representan las predicciones y las etiquetas respectivamente. Calcula la precisión y el puntaje F1 utilizando las funciones \"ACCURACY.compute\" y \"FSCORE.compute\", respectivamente, y devuelve un diccionario con las métricas \"accuracy\" y \"f1\"."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"Zvhb4iCGaj2v"},"outputs":[],"source":["def transform_test(batch: dict) -\u003e dict:\n","  \"\"\"Transform images accoding to ViT requirements\"\"\"\n","  inputs = FEATURE_EXTRACTOR(\n","      [x.convert(\"RGB\") for x in batch[\"image\"]],\n","      return_tensors=\"pt\"\n","  )\n","  return inputs\n","\n","def compute_metrics_inference(preds: list, labels: list) -\u003e dict:\n","    \"Compute accuracy and F1 score\"\n","    accuracy = ACCURACY.compute(\n","        predictions=preds,\n","        references=labels\n","    )\n","    f_score = FSCORE.compute(\n","        predictions=preds,\n","        references=labels\n","    )\n","    return {\n","        \"accuracy\": accuracy,\n","        \"f1\": f_score\n","    }"]},{"cell_type":"markdown","metadata":{"id":"PFI00AFoLsC3"},"source":["A continuación, tenemos un script que realiza la inferencia en un conjunto de prueba de una red neuronal de clasificación de imágenes previamente entrenada.\n","\n","El script utiliza la biblioteca \"Weights and Biases\" (W\u0026B) para llevar a cabo el proceso de inferencia.\n","\n","El primer bloque de código crea un nuevo \"run\" (ejecución) en el proyecto W\u0026B especificado por la constante WANDB_PROJECT_NAME y le da el nombre \"inference_test_set\".\n","\n","Luego, conecta un artifact (modelo previamente entrenado) a este nuevo run, descargándolo de W\u0026B.\n","\n","Después, descarga un conjunto de prueba desde W\u0026B y lo carga en memoria.\n","\n","A continuación, crea un pipeline de inferencia usando la biblioteca \"transformers\" que se compone de tres elementos: un modelo previamente entrenado, un tokenizador (la función \"transform_test\") y una GPU.\n","\n","El script hace una inferencia sobre cada imagen del conjunto de prueba y guarda las salidas en una lista.\n","\n","Por último, el script calcula las métricas de rendimiento (accuracy y f1 score) usando las salidas y las etiquetas verdaderas del conjunto de prueba, y finaliza el run en W\u0026B."]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":35,"status":"aborted","timestamp":1675790647038,"user":{"displayName":"Carlos Germán Sellers Mendo","userId":"10483787242844398475"},"user_tz":-60},"id":"LGrMXqhSxktz"},"outputs":[],"source":["# Create a new run\n","    # initialize new run\n","with wandb.init(\n","    project=WANDB_PROJECT_NAME,\n","    name=\"inference_test_set\"\n",") as run:\n","\n","\n","    # Connect an Artifact to the run\n","    #best_model_name = \"anban-dl/NEW_vit-image-classification-glacier/model-z81po1u1:v0\"\n","    best_model_name = \"jhbogasperona1970/vit-clasificacion/model-z81po1u1:v0\"\n","    best_model_at = run.use_artifact(best_model_name)\n","\n","    # Download model weights to a folder and return the path\n","    model_dir = best_model_at.download()\n","\n","    # download dataset from W\u0026B\n","    #test_dataset = run.use_artifact(\"anban-dl/NEW_vit-image-classification-glacier/rock-glacier-dataset_test:v0\")\n","    test_dataset = run.use_artifact(\"jhbogasperona1970/vit-clasificacion/rock-glacier-dataset_test:v0\")\n","    data_dir = test_dataset.download()\n","    test_dataset = load_from_disk(data_dir)\n","    # extract label names\n","    labels = test_dataset.features['labels'].names\n","    label2id = {c: str(i) for i, c in enumerate(labels)}\n","\n","    # pipeline for inference\n","    pipe = pipeline(\n","        task='image-classification',\n","        model=model_dir,\n","        tokenizer=transform_test,\n","        device=0 # GPU\n","    )\n","    # get predictions\n","    outputs = []\n","    for output in pipe(test_dataset[\"image\"]):\n","        outputs.append(output)\n","    \n","    preds = [label2id[out[0][\"label\"]] for out in outputs]\n","    # compute metrics\n","    metrics = compute_metrics_inference(preds, test_dataset[\"labels\"])\n","    run.finish()"]},{"cell_type":"markdown","metadata":{"id":"3vgGkBj28Uln"},"source":["Necesitamos pasar un dict `{\"pixel_values\": tensor(---)}`\n","\n","Aunque hayamos guardado los dataset preprocesador en W\u0026B por reproducibilidad, tenemos que volver a transformar las imágenes.\n","\n","Utilizamos una pipeline para realizar la inferencia de forma más cómoda y utilizando la GPU para acelerar los cálculos."]},{"cell_type":"markdown","metadata":{"id":"lN6D91fmMR1U"},"source":["metrics es una variable en el código que almacena los resultados de la función compute_metrics_inference(). La función compute_metrics_inference toma dos listas de entrada, preds y labels, y devuelve un diccionario con las métricas computadas, que incluyen la precisión y el puntaje F1. Por lo tanto, la variable metrics contendrá un diccionario con las métricas calculadas de la inferencia en el modelo de clasificación de imágenes."]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":34,"status":"aborted","timestamp":1675790647038,"user":{"displayName":"Carlos Germán Sellers Mendo","userId":"10483787242844398475"},"user_tz":-60},"id":"4BhXshjZgoqR"},"outputs":[],"source":["metrics"]},{"cell_type":"markdown","metadata":{"id":"dBqAw7Q9gx-s"},"source":["Vamos que obtenemos alrededor de un 78% de accuracy y f1 score en el cojunto de testeo.\n","\n","Si comparamos estos valores con las misma métricas de nuestro mejor modelo en el cojunto de validación, vemos que hay una diferencia considerable (97% en cojunto de validación). Esta diferencia quiere decir que nuestro modelo no generaliza tan bien cómo cabía esperar.\n","\n","Esto puede ser debido a:\n","- El conjunto de validación es bastante más pequeño que el de testeo y puede que no sea representativo o esté desbalanceado (más imágenes de una clase que de otra). Deberíamos comprobar esto\n","- Nuestro modelo esté sobreajustado en los datos de entrenamiento y validación -\u003e podríamos cambiar nuestro criterio de elección del mejor modelo y utlizar K-fold cross-validation solo con el training set"]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","name":"","provenance":[{"file_id":"12NYg4v-pcnA-vRY40iYSCaznHBg-HNvT","timestamp":1675789594251}],"version":""},"gpuClass":"premium","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"0641ba85d119461b92c63650e1cd3d14":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"10baafcf46fb49a4ac22bc33c005fb24":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"LabelModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c8126b2464db4f22896bffa25cde07d1","placeholder":"​","style":"IPY_MODEL_5a9172dd871044d8be51f33a98f60d1e","value":"0.001 MB of 0.009 MB uploaded (0.000 MB deduped)\r"}},"15223363e38f45a7b8a3a1801dd609cb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_c47e5cee09da439792ca4249cccf1e16","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0641ba85d119461b92c63650e1cd3d14","value":1}},"185b28b05a6b4b2494120cacd93cc0dc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"19e52a526f8e4e229ec62585d6c4e5c0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1e80ed7f3ba948918ec6639a3dfd5bbe":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"215654c9aa4041f9b855c5f24e17a94b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"31e1bd1b599344018f3e7c4e463d8491":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3b6ae240abd04869b85fab9eb0c7313f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"VBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"VBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"VBoxView","box_style":"","children":["IPY_MODEL_10baafcf46fb49a4ac22bc33c005fb24","IPY_MODEL_efcaf723288a4fa1b7780fc06be4fc4c"],"layout":"IPY_MODEL_8b22085156674ce0a3d7501e4fc7c911"}},"3b7469092a2f488cb464dcbdff960a9a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ade5f6f2d6974b6b866c2530d5c4b2a6","placeholder":"​","style":"IPY_MODEL_b36efe7a93f04d09b12e7e59e2847303","value":"Downloading (…)lve/main/config.json: 100%"}},"3cbeb40da7b94f73899c2888e15e2616":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4a46c9e3229f467faa93ab30dab4456a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4b8b6b26f9d646f8907cb0b19e7fb563":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"VBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"VBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"VBoxView","box_style":"","children":["IPY_MODEL_d1d4365c893d4f7db4a2827ec88d0b27","IPY_MODEL_15223363e38f45a7b8a3a1801dd609cb"],"layout":"IPY_MODEL_ac302a4f12a043f0a621960bb72b0d06"}},"524aaacfe2c246deb6945e29e4b5928e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"55533848ccb74cc2b33d449784ab79e1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"569bc0fa87b74020a7a082ddcb7af8f7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5a9172dd871044d8be51f33a98f60d1e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5b03229ff15b429bb10a60fe13c0021e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5fffbfe3fde342268d4c567d380d9319":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"630646821a574913812363d14aa83749":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ded577862a754c58951485918cbd5560","IPY_MODEL_9bad461d5eb546a189993e4f846dc1bf","IPY_MODEL_bb78794594184a96bd63fee869ac505e"],"layout":"IPY_MODEL_a305ba8aadf9410e820fb1ecb48c68f9"}},"6325f8cee5164188ba148323c31d1204":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"63bd54cd383046bd8a52a6d937df7b22":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"VBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"VBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"VBoxView","box_style":"","children":["IPY_MODEL_e0c7c16b18f942ca841302027384462f","IPY_MODEL_a06bb0db7d734a7bbd836cfd57c0a5be"],"layout":"IPY_MODEL_5fffbfe3fde342268d4c567d380d9319"}},"67edfa168ce94b678e66a807f7e2756d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"79889d5b4d90426aa20e7295f0b7b62b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8828893dd0ce434b877b9ba748ffc3a0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5b03229ff15b429bb10a60fe13c0021e","placeholder":"​","style":"IPY_MODEL_4a46c9e3229f467faa93ab30dab4456a","value":" 502/502 [00:00\u0026lt;00:00, 5.09kB/s]"}},"8b22085156674ce0a3d7501e4fc7c911":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"912e0e96aa384e6ba81922a631a5fda2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9bad461d5eb546a189993e4f846dc1bf":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_79889d5b4d90426aa20e7295f0b7b62b","max":345636463,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1e80ed7f3ba948918ec6639a3dfd5bbe","value":345636463}},"a06bb0db7d734a7bbd836cfd57c0a5be":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_67edfa168ce94b678e66a807f7e2756d","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_19e52a526f8e4e229ec62585d6c4e5c0","value":1}},"a305ba8aadf9410e820fb1ecb48c68f9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ac302a4f12a043f0a621960bb72b0d06":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ade5f6f2d6974b6b866c2530d5c4b2a6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b36efe7a93f04d09b12e7e59e2847303":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bb78794594184a96bd63fee869ac505e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cf2412ab11aa49b3a56ad005d26d3583","placeholder":"​","style":"IPY_MODEL_d79ac149e61c4b5f8355fbcfb058573e","value":" 346M/346M [00:03\u0026lt;00:00, 90.4MB/s]"}},"c47e5cee09da439792ca4249cccf1e16":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c8126b2464db4f22896bffa25cde07d1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cf2412ab11aa49b3a56ad005d26d3583":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cf41d8a3a7bc4023adecbe9833257d1e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3b7469092a2f488cb464dcbdff960a9a","IPY_MODEL_df4767785d9f425b8ad91c3bf6f25dc6","IPY_MODEL_8828893dd0ce434b877b9ba748ffc3a0"],"layout":"IPY_MODEL_31e1bd1b599344018f3e7c4e463d8491"}},"d1d4365c893d4f7db4a2827ec88d0b27":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"LabelModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_569bc0fa87b74020a7a082ddcb7af8f7","placeholder":"​","style":"IPY_MODEL_912e0e96aa384e6ba81922a631a5fda2","value":"0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\r"}},"d79ac149e61c4b5f8355fbcfb058573e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ded577862a754c58951485918cbd5560":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6325f8cee5164188ba148323c31d1204","placeholder":"​","style":"IPY_MODEL_fd9dd37c1c6a40dbbecd188d715d2675","value":"Downloading (…)\u0026quot;pytorch_model.bin\u0026quot;;: 100%"}},"df4767785d9f425b8ad91c3bf6f25dc6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_524aaacfe2c246deb6945e29e4b5928e","max":502,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f00063644c004e0b83bfd0c7a7646dfb","value":502}},"e0c7c16b18f942ca841302027384462f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"LabelModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3cbeb40da7b94f73899c2888e15e2616","placeholder":"​","style":"IPY_MODEL_185b28b05a6b4b2494120cacd93cc0dc","value":"Waiting for wandb.init()...\r"}},"efcaf723288a4fa1b7780fc06be4fc4c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_55533848ccb74cc2b33d449784ab79e1","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_215654c9aa4041f9b855c5f24e17a94b","value":0.08235423300757659}},"f00063644c004e0b83bfd0c7a7646dfb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"fd9dd37c1c6a40dbbecd188d715d2675":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}