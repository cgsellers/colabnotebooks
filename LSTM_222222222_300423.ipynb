{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0nLJpDaQNNZ5","outputId":"7d96a85b-c0d2-4c28-920d-c5dae4f8c8aa","executionInfo":{"status":"ok","timestamp":1683128467499,"user_tz":-120,"elapsed":209295,"user":{"displayName":"Carlos Germán Sellers Mendo","userId":"10483787242844398475"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Había una vez tres cerditos que eran hermanos y se fueron por el mundo a conseguir fortuna. El más grande les dijo a sus hermanos que sería bueno que se pusieran a construir sus propias casas para estar protegidos. A los otros dos les pareció una buena idea, y se pusieron manos a la obra, cada uno construyó su casita.  - La mía será de paja - dijo el más pequeño-, la paja es blanda y se puede sujetar con facilidad. Terminaré muy pronto y podré ir a jugar. El hermano mediano decidió que su casa sería de madera:  - Puedo encontrar un montón de madera por los alrededores - explicó a sus hermanos, - Construiré mi casa en un santiamén con todos estos troncos y me iré también a jugar.  Cuando las tres casitas estuvieron terminadas, los cerditos cantaban y bailaban en la puerta, felices por haber acabado con el problema:  -¡Quién teme al Lobo Feroz, al Lobo, al Lobo!  - ¡Quién teme al Lobo Feroz, al Lobo Feroz! Detrás de un árbol grande apareció el lobo, rugiendo de hambre y gritando:  - Cerditos, ¡me los voy a comer! Cada uno se escondió en su casa, pensando que estaban a salvo, pero el Lobo Feroz se encaminó a la casita de paja del hermano pequeño y en la puerta aulló:  - ¡Cerdito, ábreme la puerta!  - No, no, no, no te voy a abrir. - Pues si no me abres... ¡Soplaré y soplaré y la casita derribaré! Y sopló con todas sus fuerzas, sopló y sopló y la casita de paja se vino abajo. El cerdito pequeño corrió lo más rápido que pudo y entró en la casa de madera del hermano mediano. - ¡Quién teme al Lobo Feroz, al Lobo, al Lobo!  - ¡Quién teme al Lobo Feroz, al Lobo Feroz! - cantaban desde dentro los cerditos.  De nuevo el Lobo, más enfurecido que antes al sentirse engañado, se colocó delante de la puerta y comenzó a soplar y soplar gruñendo: - ¡Cerditos, abridme la puerta! - No, no, no, no te vamos a abrir. - Pues si no me abrís... ¡Soplaré y soplaré y la casita derribaré! La madera crujió, y las paredes cayeron y los dos cerditos corrieron a refugiarse en la casa de ladrillo de su hermano mayor.  - ¡Quién teme al Lobo Feroz, al Lobo, al Lobo!  - ¡Quién teme al Lobo Feroz, al Lobo Feroz! - cantaban desde dentro los cerditos. El lobo estaba realmente enfadado y hambriento, y ahora deseaba comerse a los Tres Cerditos más que nunca, y frente a la puerta dijo:  - ¡Cerditos, abridme la puerta! - No, no, no, no te vamos a abrir.  - Pues si no me abrís... ¡Soplaré y soplaré y la casita derribaré!  Y se puso a soplar tan fuerte como el viento de invierno. Sopló y sopló, pero la casita de ladrillos era muy resistente y no conseguía derribarla. Decidió trepar por la pared y entrar por la chimenea. Se deslizó hacia abajo... Y cayó en el caldero donde el cerdito mayor estaba hirviendo sopa de nabos. Escaldado y con el estómago vacío salió huyendo hacia el lago. Los cerditos no lo volvieron a ver.  El mayor de ellos regañó a los otros dos por haber sido tan perezosos y poner en peligro sus propias vidas, y si algún día vais por el bosque y veis tres cerdos, sabréis que son los Tres Cerditos porque les gusta cantar:  - ¡Quién teme al Lobo Feroz, al Lobo, al Lobo!  - ¡Quién teme al Lobo Feroz, al Lobo Feroz!\n","['Había una vez tres cerditos que eran hermanos y se fueron por el mundo a conseguir fortuna', ' El más grande les dijo a sus hermanos que sería bueno que se pusieran a construir sus propias casas para estar protegidos', ' A los otros dos les pareció una buena idea, y se pusieron manos a la obra, cada uno construyó su casita', '  - La mía será de paja - dijo el más pequeño-, la paja es blanda y se puede sujetar con facilidad', ' Terminaré muy pronto y podré ir a jugar', ' El hermano mediano decidió que su casa sería de madera:  - Puedo encontrar un montón de madera por los alrededores - explicó a sus hermanos, - Construiré mi casa en un santiamén con todos estos troncos y me iré también a jugar', '  Cuando las tres casitas estuvieron terminadas, los cerditos cantaban y bailaban en la puerta, felices por haber acabado con el problema:  -¡Quién teme al Lobo Feroz, al Lobo, al Lobo!  - ¡Quién teme al Lobo Feroz, al Lobo Feroz! Detrás de un árbol grande apareció el lobo, rugiendo de hambre y gritando:  - Cerditos, ¡me los voy a comer! Cada uno se escondió en su casa, pensando que estaban a salvo, pero el Lobo Feroz se encaminó a la casita de paja del hermano pequeño y en la puerta aulló:  - ¡Cerdito, ábreme la puerta!  - No, no, no, no te voy a abrir', ' - Pues si no me abres', '', '', ' ¡Soplaré y soplaré y la casita derribaré! Y sopló con todas sus fuerzas, sopló y sopló y la casita de paja se vino abajo', ' El cerdito pequeño corrió lo más rápido que pudo y entró en la casa de madera del hermano mediano', ' - ¡Quién teme al Lobo Feroz, al Lobo, al Lobo!  - ¡Quién teme al Lobo Feroz, al Lobo Feroz! - cantaban desde dentro los cerditos', '  De nuevo el Lobo, más enfurecido que antes al sentirse engañado, se colocó delante de la puerta y comenzó a soplar y soplar gruñendo: - ¡Cerditos, abridme la puerta! - No, no, no, no te vamos a abrir', ' - Pues si no me abrís', '', '', ' ¡Soplaré y soplaré y la casita derribaré! La madera crujió, y las paredes cayeron y los dos cerditos corrieron a refugiarse en la casa de ladrillo de su hermano mayor', '  - ¡Quién teme al Lobo Feroz, al Lobo, al Lobo!  - ¡Quién teme al Lobo Feroz, al Lobo Feroz! - cantaban desde dentro los cerditos', ' El lobo estaba realmente enfadado y hambriento, y ahora deseaba comerse a los Tres Cerditos más que nunca, y frente a la puerta dijo:  - ¡Cerditos, abridme la puerta! - No, no, no, no te vamos a abrir', '  - Pues si no me abrís', '', '', ' ¡Soplaré y soplaré y la casita derribaré!  Y se puso a soplar tan fuerte como el viento de invierno', ' Sopló y sopló, pero la casita de ladrillos era muy resistente y no conseguía derribarla', ' Decidió trepar por la pared y entrar por la chimenea', ' Se deslizó hacia abajo', '', '', ' Y cayó en el caldero donde el cerdito mayor estaba hirviendo sopa de nabos', ' Escaldado y con el estómago vacío salió huyendo hacia el lago', ' Los cerditos no lo volvieron a ver', '  El mayor de ellos regañó a los otros dos por haber sido tan perezosos y poner en peligro sus propias vidas, y si algún día vais por el bosque y veis tres cerdos, sabréis que son los Tres Cerditos porque les gusta cantar:  - ¡Quién teme al Lobo Feroz, al Lobo, al Lobo!  - ¡Quién teme al Lobo Feroz, al Lobo Feroz!']\n","Epoch 1/100\n","18/18 [==============================] - 4s 80ms/step - loss: 5.3887 - accuracy: 0.0385\n","Epoch 2/100\n","18/18 [==============================] - 1s 80ms/step - loss: 5.0576 - accuracy: 0.0385\n","Epoch 3/100\n","18/18 [==============================] - 2s 122ms/step - loss: 4.8260 - accuracy: 0.0624\n","Epoch 4/100\n","18/18 [==============================] - 2s 99ms/step - loss: 4.7923 - accuracy: 0.0587\n","Epoch 5/100\n","18/18 [==============================] - 1s 79ms/step - loss: 4.7899 - accuracy: 0.0569\n","Epoch 6/100\n","18/18 [==============================] - 1s 79ms/step - loss: 4.7743 - accuracy: 0.0606\n","Epoch 7/100\n","18/18 [==============================] - 1s 80ms/step - loss: 4.7657 - accuracy: 0.0606\n","Epoch 8/100\n","18/18 [==============================] - 1s 80ms/step - loss: 4.7695 - accuracy: 0.0459\n","Epoch 9/100\n","18/18 [==============================] - 1s 79ms/step - loss: 4.7684 - accuracy: 0.0550\n","Epoch 10/100\n","18/18 [==============================] - 1s 80ms/step - loss: 4.7548 - accuracy: 0.0716\n","Epoch 11/100\n","18/18 [==============================] - 2s 110ms/step - loss: 4.7420 - accuracy: 0.0734\n","Epoch 12/100\n","18/18 [==============================] - 2s 113ms/step - loss: 4.7319 - accuracy: 0.0752\n","Epoch 13/100\n","18/18 [==============================] - 1s 78ms/step - loss: 4.6940 - accuracy: 0.0991\n","Epoch 14/100\n","18/18 [==============================] - 1s 77ms/step - loss: 4.6742 - accuracy: 0.0936\n","Epoch 15/100\n","18/18 [==============================] - 1s 79ms/step - loss: 4.6167 - accuracy: 0.0991\n","Epoch 16/100\n","18/18 [==============================] - 1s 80ms/step - loss: 4.5861 - accuracy: 0.0991\n","Epoch 17/100\n","18/18 [==============================] - 1s 79ms/step - loss: 4.5296 - accuracy: 0.1156\n","Epoch 18/100\n","18/18 [==============================] - 1s 78ms/step - loss: 4.4783 - accuracy: 0.1193\n","Epoch 19/100\n","18/18 [==============================] - 1s 81ms/step - loss: 4.4465 - accuracy: 0.1248\n","Epoch 20/100\n","18/18 [==============================] - 2s 117ms/step - loss: 4.4122 - accuracy: 0.1229\n","Epoch 21/100\n","18/18 [==============================] - 2s 95ms/step - loss: 4.3754 - accuracy: 0.1339\n","Epoch 22/100\n","18/18 [==============================] - 1s 80ms/step - loss: 4.3391 - accuracy: 0.1229\n","Epoch 23/100\n","18/18 [==============================] - 1s 80ms/step - loss: 4.2916 - accuracy: 0.1431\n","Epoch 24/100\n","18/18 [==============================] - 1s 79ms/step - loss: 4.2410 - accuracy: 0.1394\n","Epoch 25/100\n","18/18 [==============================] - 1s 79ms/step - loss: 4.2163 - accuracy: 0.1413\n","Epoch 26/100\n","18/18 [==============================] - 1s 81ms/step - loss: 4.2968 - accuracy: 0.1321\n","Epoch 27/100\n","18/18 [==============================] - 1s 78ms/step - loss: 4.1863 - accuracy: 0.1560\n","Epoch 28/100\n","18/18 [==============================] - 2s 105ms/step - loss: 4.1332 - accuracy: 0.1560\n","Epoch 29/100\n","18/18 [==============================] - 2s 113ms/step - loss: 4.0653 - accuracy: 0.1651\n","Epoch 30/100\n","18/18 [==============================] - 1s 80ms/step - loss: 4.0231 - accuracy: 0.1578\n","Epoch 31/100\n","18/18 [==============================] - 1s 78ms/step - loss: 3.9806 - accuracy: 0.1743\n","Epoch 32/100\n","18/18 [==============================] - 1s 79ms/step - loss: 3.9247 - accuracy: 0.1725\n","Epoch 33/100\n","18/18 [==============================] - 2s 94ms/step - loss: 3.8701 - accuracy: 0.1872\n","Epoch 34/100\n","18/18 [==============================] - 1s 79ms/step - loss: 3.8102 - accuracy: 0.1798\n","Epoch 35/100\n","18/18 [==============================] - 1s 77ms/step - loss: 3.7640 - accuracy: 0.1872\n","Epoch 36/100\n","18/18 [==============================] - 2s 92ms/step - loss: 3.6928 - accuracy: 0.1927\n","Epoch 37/100\n","18/18 [==============================] - 2s 117ms/step - loss: 3.6322 - accuracy: 0.2037\n","Epoch 38/100\n","18/18 [==============================] - 2s 84ms/step - loss: 3.5780 - accuracy: 0.2183\n","Epoch 39/100\n","18/18 [==============================] - 1s 77ms/step - loss: 3.5328 - accuracy: 0.1963\n","Epoch 40/100\n","18/18 [==============================] - 1s 78ms/step - loss: 3.4574 - accuracy: 0.2312\n","Epoch 41/100\n","18/18 [==============================] - 1s 79ms/step - loss: 3.4054 - accuracy: 0.2294\n","Epoch 42/100\n","18/18 [==============================] - 1s 80ms/step - loss: 3.3631 - accuracy: 0.2367\n","Epoch 43/100\n","18/18 [==============================] - 1s 81ms/step - loss: 3.2674 - accuracy: 0.2440\n","Epoch 44/100\n","18/18 [==============================] - 1s 79ms/step - loss: 3.1863 - accuracy: 0.2624\n","Epoch 45/100\n","18/18 [==============================] - 2s 116ms/step - loss: 3.1369 - accuracy: 0.2661\n","Epoch 46/100\n","18/18 [==============================] - 2s 104ms/step - loss: 3.1089 - accuracy: 0.2606\n","Epoch 47/100\n","18/18 [==============================] - 1s 77ms/step - loss: 3.0571 - accuracy: 0.2844\n","Epoch 48/100\n","18/18 [==============================] - 1s 79ms/step - loss: 2.9851 - accuracy: 0.2844\n","Epoch 49/100\n","18/18 [==============================] - 1s 80ms/step - loss: 2.8858 - accuracy: 0.3083\n","Epoch 50/100\n","18/18 [==============================] - 1s 81ms/step - loss: 2.8221 - accuracy: 0.3229\n","Epoch 51/100\n","18/18 [==============================] - 1s 80ms/step - loss: 2.7623 - accuracy: 0.3156\n","Epoch 52/100\n","18/18 [==============================] - 2s 86ms/step - loss: 2.7596 - accuracy: 0.3101\n","Epoch 53/100\n","18/18 [==============================] - 2s 107ms/step - loss: 2.6955 - accuracy: 0.3450\n","Epoch 54/100\n","18/18 [==============================] - 2s 119ms/step - loss: 2.5999 - accuracy: 0.3578\n","Epoch 55/100\n","18/18 [==============================] - 1s 80ms/step - loss: 2.5507 - accuracy: 0.3615\n","Epoch 56/100\n","18/18 [==============================] - 1s 79ms/step - loss: 2.5054 - accuracy: 0.3945\n","Epoch 57/100\n","18/18 [==============================] - 1s 80ms/step - loss: 2.4684 - accuracy: 0.3963\n","Epoch 58/100\n","18/18 [==============================] - 1s 79ms/step - loss: 2.4481 - accuracy: 0.4092\n","Epoch 59/100\n","18/18 [==============================] - 1s 81ms/step - loss: 2.3511 - accuracy: 0.4147\n","Epoch 60/100\n","18/18 [==============================] - 1s 79ms/step - loss: 2.2892 - accuracy: 0.4459\n","Epoch 61/100\n","18/18 [==============================] - 2s 84ms/step - loss: 2.2240 - accuracy: 0.4532\n","Epoch 62/100\n","18/18 [==============================] - 2s 121ms/step - loss: 2.1624 - accuracy: 0.4899\n","Epoch 63/100\n","18/18 [==============================] - 2s 90ms/step - loss: 2.1033 - accuracy: 0.4991\n","Epoch 64/100\n","18/18 [==============================] - 1s 80ms/step - loss: 2.0638 - accuracy: 0.5119\n","Epoch 65/100\n","18/18 [==============================] - 1s 80ms/step - loss: 2.0070 - accuracy: 0.5174\n","Epoch 66/100\n","18/18 [==============================] - 1s 80ms/step - loss: 1.9811 - accuracy: 0.5394\n","Epoch 67/100\n","18/18 [==============================] - 1s 80ms/step - loss: 1.9462 - accuracy: 0.5541\n","Epoch 68/100\n","18/18 [==============================] - 1s 77ms/step - loss: 1.9164 - accuracy: 0.5560\n","Epoch 69/100\n","18/18 [==============================] - 1s 78ms/step - loss: 1.8737 - accuracy: 0.5688\n","Epoch 70/100\n","18/18 [==============================] - 2s 103ms/step - loss: 1.8501 - accuracy: 0.5725\n","Epoch 71/100\n","18/18 [==============================] - 2s 113ms/step - loss: 1.7695 - accuracy: 0.6092\n","Epoch 72/100\n","18/18 [==============================] - 1s 78ms/step - loss: 1.7513 - accuracy: 0.6110\n","Epoch 73/100\n","18/18 [==============================] - 1s 77ms/step - loss: 1.7153 - accuracy: 0.6220\n","Epoch 74/100\n","18/18 [==============================] - 1s 78ms/step - loss: 1.7142 - accuracy: 0.6110\n","Epoch 75/100\n","18/18 [==============================] - 1s 78ms/step - loss: 1.6397 - accuracy: 0.6495\n","Epoch 76/100\n","18/18 [==============================] - 1s 79ms/step - loss: 1.6059 - accuracy: 0.6514\n","Epoch 77/100\n","18/18 [==============================] - 1s 79ms/step - loss: 1.5589 - accuracy: 0.6716\n","Epoch 78/100\n","18/18 [==============================] - 1s 77ms/step - loss: 1.5151 - accuracy: 0.6972\n","Epoch 79/100\n","18/18 [==============================] - 2s 119ms/step - loss: 1.4762 - accuracy: 0.7156\n","Epoch 80/100\n","18/18 [==============================] - 2s 97ms/step - loss: 1.4472 - accuracy: 0.7211\n","Epoch 81/100\n","18/18 [==============================] - 1s 78ms/step - loss: 1.4492 - accuracy: 0.7101\n","Epoch 82/100\n","18/18 [==============================] - 1s 78ms/step - loss: 1.3946 - accuracy: 0.7486\n","Epoch 83/100\n","18/18 [==============================] - 1s 80ms/step - loss: 1.4125 - accuracy: 0.6972\n","Epoch 84/100\n","18/18 [==============================] - 1s 79ms/step - loss: 1.3609 - accuracy: 0.7394\n","Epoch 85/100\n","18/18 [==============================] - 1s 78ms/step - loss: 1.3383 - accuracy: 0.7303\n","Epoch 86/100\n","18/18 [==============================] - 1s 78ms/step - loss: 1.2903 - accuracy: 0.7596\n","Epoch 87/100\n","18/18 [==============================] - 2s 99ms/step - loss: 1.2495 - accuracy: 0.7725\n","Epoch 88/100\n","18/18 [==============================] - 2s 122ms/step - loss: 1.2332 - accuracy: 0.7670\n","Epoch 89/100\n","18/18 [==============================] - 1s 80ms/step - loss: 1.2200 - accuracy: 0.7853\n","Epoch 90/100\n","18/18 [==============================] - 1s 79ms/step - loss: 1.1823 - accuracy: 0.7798\n","Epoch 91/100\n","18/18 [==============================] - 1s 81ms/step - loss: 1.1473 - accuracy: 0.7853\n","Epoch 92/100\n","18/18 [==============================] - 1s 80ms/step - loss: 1.1064 - accuracy: 0.7963\n","Epoch 93/100\n","18/18 [==============================] - 1s 78ms/step - loss: 1.0923 - accuracy: 0.8055\n","Epoch 94/100\n","18/18 [==============================] - 1s 79ms/step - loss: 1.1328 - accuracy: 0.7927\n","Epoch 95/100\n","18/18 [==============================] - 1s 77ms/step - loss: 1.0816 - accuracy: 0.8128\n","Epoch 96/100\n","18/18 [==============================] - 2s 120ms/step - loss: 1.0487 - accuracy: 0.8202\n","Epoch 97/100\n","18/18 [==============================] - 2s 98ms/step - loss: 1.0021 - accuracy: 0.8422\n","Epoch 98/100\n","18/18 [==============================] - 1s 79ms/step - loss: 0.9593 - accuracy: 0.8569\n","Epoch 99/100\n","18/18 [==============================] - 1s 80ms/step - loss: 0.9657 - accuracy: 0.8495\n","Epoch 100/100\n","18/18 [==============================] - 1s 80ms/step - loss: 0.9455 - accuracy: 0.8349\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f6d7618fd90>"]},"metadata":{},"execution_count":1}],"source":["import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Input\n","from tensorflow.keras.models import Model\n","\n","import numpy as np\n","\n","# Lee el archivo de texto y crea una lista de oraciones\n","with open('los3.txt', 'r') as file:\n","    data = file.read().replace('\\n', '')\n","\n","print(data)\n","sentences = data.split('.')\n","print(sentences)    \n","# Tokeniza las oraciones\n","tokenizer = Tokenizer(num_words=5000)\n","tokenizer.fit_on_texts(sentences)\n","total_words = len(tokenizer.word_index) + 1\n","\n","# Crea secuencias de palabras para el entrenamiento del modelo\n","input_sequences = []\n","for line in sentences:\n","    token_list = tokenizer.texts_to_sequences([line])[0]\n","    for i in range(1, len(token_list)):\n","        n_gram_sequence = token_list[:i+1]\n","        input_sequences.append(n_gram_sequence)\n","\n","# Obtiene la longitud máxima de secuencia y rellena las secuencias para que tengan la misma longitud\n","max_sequence_len = max([len(x) for x in input_sequences])\n","input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n","\n","# Crea los datos de entrada y salida para el modelo\n","xs, labels = input_sequences[:,:-1],input_sequences[:,-1]\n","\n","ys = tf.keras.utils.to_categorical(labels, num_classes=total_words)\n","\n","# Crea el modelo de red neuronal\n","input_layer = Input(shape=(max_sequence_len-1,))\n","embedding_layer = Embedding(total_words, 10, input_length=max_sequence_len-1)(input_layer)\n","lstm_layer = LSTM(100)(embedding_layer)\n","dropout_layer = Dropout(0.1)(lstm_layer)\n","output_layer = Dense(total_words, activation='softmax')(dropout_layer)\n","model = Model(inputs=input_layer, outputs=output_layer)\n","model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","\n","# Entrena el modelo\n","model.fit(xs, ys, epochs=100, verbose=1)\n"]},{"cell_type":"code","source":["import re"],"metadata":{"id":"f60_tDRMaZDQ","executionInfo":{"status":"ok","timestamp":1683128467500,"user_tz":-120,"elapsed":13,"user":{"displayName":"Carlos Germán Sellers Mendo","userId":"10483787242844398475"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["# Crear un diccionario de caracteres únicos y asignar un número a cada uno\n","char_to_idx = {char: idx for idx, char in enumerate(sorted(set(data)))}\n","\n","# Crear el diccionario inverso\n","idx_to_char = {idx: char for char, idx in char_to_idx.items()}"],"metadata":{"id":"gWmfM_1saq-Z","executionInfo":{"status":"ok","timestamp":1683128467500,"user_tz":-120,"elapsed":9,"user":{"displayName":"Carlos Germán Sellers Mendo","userId":"10483787242844398475"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["# Longitud de secuencia para la entrada del modelo\n","seq_length = 100"],"metadata":{"id":"hN89U0Oxa5D_","executionInfo":{"status":"ok","timestamp":1683128467501,"user_tz":-120,"elapsed":9,"user":{"displayName":"Carlos Germán Sellers Mendo","userId":"10483787242844398475"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["def generate_text(model, start_string, num_generate=10, temperature=0.1):\n","    print(start_string)\n","    string = start_string.lower()\n","    print(string)\n","    string = re.sub(r'[^a-zñáéíóúü]', ' ', string)\n","    input_eval = [char_to_idx[char] for char in string]\n","    if len(input_eval) < max_sequence_len-1:\n","        input_eval = tf.pad(input_eval, [(0, max_sequence_len-1 - len(input_eval))], mode='CONSTANT', constant_values=0)\n","    else:\n","        input_eval = np.roll(input_eval, max_sequence_len-1-(len(input_eval)-1))\n","    input_eval = tf.reshape(input_eval, (1, max_sequence_len-1))\n","\n","    # Crear una lista vacía para almacenar el texto generado\n","    text_generated = []\n","\n","    # Establecer la temperatura\n","    model.reset_states()\n","    temperature = temperature\n","\n","    for i in range(num_generate):\n","        # Predecir el siguiente carácter utilizando el modelo\n","        predictions = model(input_eval)\n","        predictions = predictions / temperature\n","        \n","        predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n","        predicted_id = predicted_id if predicted_id < len(idx_to_char) else len(idx_to_char) - 1\n","\n","        # Añadir el carácter generado a la lista de texto generado\n","        text_generated.append(idx_to_char[predicted_id])\n","\n","        # Utilizar el carácter generado como entrada para la siguiente predicción\n","        input_eval = tf.concat([input_eval[:, 1:], tf.expand_dims([predicted_id], 1)], axis=-1)\n","\n","    return ( ''.join(text_generated))\n","\n","\n","\n"],"metadata":{"id":"1I2dBktsaIvY","executionInfo":{"status":"ok","timestamp":1683128467501,"user_tz":-120,"elapsed":9,"user":{"displayName":"Carlos Germán Sellers Mendo","userId":"10483787242844398475"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# Generar texto nuevo\n","generated_text = generate_text(model, start_string='Los Tres Cerditos', num_generate=100, temperature=1.5)\n","print()\n","# Imprimir el texto generado\n","print(generated_text)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Df5OXLCXaPjn","outputId":"c3cfc906-a441-4900-eb84-e2511920234e","executionInfo":{"status":"ok","timestamp":1683128480423,"user_tz":-120,"elapsed":12930,"user":{"displayName":"Carlos Germán Sellers Mendo","userId":"10483787242844398475"}}},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Los Tres Cerditos\n","los tres cerditos\n","\n","úúúúúú úúúYLúúDúQúúúúLúúúúúúAúDúúúúúóúúHEúúúúúbúúúúúúúúxúúúiúúúúúújúúúúíúúúNLúúúúúúúúpúúúúúúúúúúúúYú\n"]}]}]}